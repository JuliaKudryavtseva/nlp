{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6cc31c-642d-428e-94d7-8c41519c57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (66.1.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.26.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6b35a9-023c-4ff8-8739-bc978c1a4be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.file_utils import cached_property\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a913f3-d530-4177-b1a6-97a87397db80",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26c278-e3ee-4084-97f6-dac02ab584b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda:0'\n",
    "    print('GPU')\n",
    "else:\n",
    "    device='cpu'\n",
    "    print('CPU')\n",
    "    \n",
    "    \n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73cecd-abb8-4635-a184-430959e38258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_checkpoint = \"t5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171f4cc-6472-4797-883e-2cb95c4d0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx <= len(self.x['input_ids']), (idx, len(self.x['input_ids']))\n",
    "        item = {key: val[idx] for key, val in self.x.items()}\n",
    "        item['decoder_attention_mask'] = self.y['attention_mask'][idx]\n",
    "        item['labels'] = self.y['input_ids'][idx]\n",
    "        return item\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.x['input_ids'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3137b-4300-4c74-9822-6aaefce55e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "        )\n",
    "        ybatch = self.tokenizer.pad(\n",
    "            {'input_ids': batch['labels'], 'attention_mask': batch['decoder_attention_mask']},\n",
    "            padding=True,\n",
    "        ) \n",
    "        batch['labels'] = ybatch['input_ids']\n",
    "        batch['decoder_attention_mask'] = ybatch['attention_mask']\n",
    "        \n",
    "        return {k: torch.tensor(v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1229c-d458-413c-acc9-2fb0221248b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce916472-8e8c-4436-8028-9fc1ec6ac61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            loss = model(**{k: v.to(model.device) for k, v in batch.items()}).loss\n",
    "            num += len(batch) * loss.item()\n",
    "            den += len(batch)\n",
    "    val_loss = num / den\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c063e4-fa59-487c-96a0-d9a8cf7f35f5",
   "metadata": {},
   "source": [
    "# **Read data SemEval2018-Task9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2344944-6187-49b1-bcb9-0f1b98c505ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_en = \"SemEval2018-Task9/training/data/1A.english.training.data.txt\"\n",
    "path_gold_en = \"SemEval2018-Task9/training/gold/1A.english.training.gold.txt\"\n",
    "\n",
    "train_data_en = pd.read_csv(path_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "train_data_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ea460-4fcd-44c6-85f6-44af748bc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_en = 'find  : ' + train_data_en.relation + ' | term : ' + train_data_en.term\n",
    "train_data_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dc136-3d1c-4786-a681-b58d82e0a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gold_en = pd.read_csv(path_gold_en, header=None, names=['hypernym'])\n",
    "train_gold_en = train_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "train_gold_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129edda7-bf42-43e4-9fd0-7e55aa8bc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data_en = \"SemEval2018-Task9/test/data/1A.english.test.data.txt\"\n",
    "path_test_gold_en = \"SemEval2018-Task9/test/gold/1A.english.test.gold.txt\"\n",
    "\n",
    "test_data_en = pd.read_csv(path_test_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "test_data_en = 'relation : ' + test_data_en.relation + ' | term : ' + test_data_en.term\n",
    "test_data_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac01c7d-bbcf-4b69-9a94-195cc336e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gold_en = pd.read_csv(path_test_gold_en, header=None, names=['hypernym'])\n",
    "test_gold_en = test_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "test_gold_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fad45-8557-4569-85e9-84a9c8de4d1c",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664a387-5afe-4097-845d-961c6c3a7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, max_length=100, block_size=64)\n",
    "\n",
    "train_dataset = PairsDataset(tokenizer(train_data_en.tolist()), tokenizer(train_gold_en.tolist()))\n",
    "test_dataset = PairsDataset(tokenizer(test_data_en.tolist()), tokenizer(test_gold_en.tolist()))\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "args = TrainingArguments(output_dir=\"t5-finetuned-large\", num_train_epochs=1, per_device_train_batch_size=16, save_steps=10000)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a494a6-1f75-4c1e-977d-481d8b857707",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec1fb2-d985-4533-9bf0-e6eb06f31f4f",
   "metadata": {},
   "source": [
    "# EVALUATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edd7e6-385b-4747-99a1-b98bba45590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_en=[]\n",
    "for i_2, j_2 in tqdm(zip(test_data_en.tolist(), test_gold_en.tolist())):\n",
    "        input_ids = tokenizer.encode(i_2, return_tensors=\"pt\")\n",
    "        output_batch = model.generate(input_ids.cuda(), no_repeat_ngram_size=2, max_new_tokens=2048, \n",
    "                                      num_return_sequences=50, num_beams=50, early_stopping=True, \n",
    "                                      num_beam_groups=5, \n",
    "                                      diversity_penalty=1.0)\n",
    "        decoded_list = []\n",
    "        for outputs in output_batch:\n",
    "            decoded = tokenizer.decode(outputs, skip_special_tokens=True).split(\", \")\n",
    "            decoded_list.extend(decoded)\n",
    "\n",
    "        predicted_answer = set(decoded_list)\n",
    "        sorted_predicted_answer = [i[0] for i in Counter(decoded_list).most_common()]\n",
    "        \n",
    "        true_answers = set(j_2.split(\", \"))\n",
    "        test_pred_en.append(true_answers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019a190-e23a-431d-86d6-e6e0f12cf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_en_df = []\n",
    "for i in test_pred_en:\n",
    "    test_pred_en_df.append(',\\t'.join(i))\n",
    "\n",
    "\n",
    "test_pred_en_df = pd.DataFrame(test_pred_en_df)\n",
    "test_pred_en_df.to_csv('test_pred_en.txt', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2940d-da6d-4a5f-b173-c292c190bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python SemEval2018-Task9/task9-scorer.py SemEval2018-Task9/test/gold/1A.english.test.gold.txt test_pred_en.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
