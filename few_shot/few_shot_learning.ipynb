{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4946738-b2f4-498b-b3e1-5232b71a9504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 31 13:14:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    28W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   35C    P8    15W / 260W |   9065MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 73%   68C    P2   161W / 260W |   9743MiB / 11264MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "|  0%   32C    P8    19W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  Off |\n",
      "|  0%   36C    P8    27W / 460W |   8082MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "|  0%   35C    P8    26W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6cc31c-642d-428e-94d7-8c41519c57fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.10.7)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (66.1.1)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.27.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6b35a9-023c-4ff8-8739-bc978c1a4be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.file_utils import cached_property\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a913f3-d530-4177-b1a6-97a87397db80",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c794ce50-1061-4dd8-b3df-a0dd720f1b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_cuda_command' from 'get_cuda_device' (/home/jovyan/work/few_shot/get_cuda_device.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mget_cuda_device\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_cuda_command\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m get_cuda_command(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_get_cuda_command' from 'get_cuda_device' (/home/jovyan/work/few_shot/get_cuda_device.py)"
     ]
    }
   ],
   "source": [
    "from get_cuda_device import _get_cuda_command\n",
    "import os\n",
    "\n",
    "get_cuda_command('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48335c5e-32a5-464c-b95e-5e85643629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09126e4-5e03-483d-8963-33a2ae3dc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 17:21:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "|  0%   32C    P8    26W / 460W |   2609MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    14W / 260W |   9065MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8     9W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "|  0%   31C    P8    18W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  Off |\n",
      "|  0%   35C    P8    29W / 460W |   4409MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    25W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a26c278-e3ee-4084-97f6-dac02ab584b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "    print('GPU')\n",
    "else:\n",
    "    device='cpu'\n",
    "    print('CPU')\n",
    "    \n",
    "    \n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec73cecd-abb8-4635-a184-430959e38258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[1;32m      3\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-large\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model2 \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_checkpoint)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_checkpoint)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_checkpoint = \"t5-large\"\n",
    "model2 = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171f4cc-6472-4797-883e-2cb95c4d0c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx <= len(self.x['input_ids']), (idx, len(self.x['input_ids']))\n",
    "        item = {key: val[idx] for key, val in self.x.items()}\n",
    "        item['decoder_attention_mask'] = self.y['attention_mask'][idx]\n",
    "        item['labels'] = self.y['input_ids'][idx]\n",
    "        return item\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.x['input_ids'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b3137b-4300-4c74-9822-6aaefce55e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "        )\n",
    "        ybatch = self.tokenizer.pad(\n",
    "            {'input_ids': batch['labels'], 'attention_mask': batch['decoder_attention_mask']},\n",
    "            padding=True,\n",
    "        ) \n",
    "        batch['labels'] = ybatch['input_ids']\n",
    "        batch['decoder_attention_mask'] = ybatch['attention_mask']\n",
    "        \n",
    "        return {k: torch.tensor(v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef1229c-d458-413c-acc9-2fb0221248b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce916472-8e8c-4436-8028-9fc1ec6ac61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            loss = model(**{k: v.to(model.device) for k, v in batch.items()}).loss\n",
    "            num += len(batch) * loss.item()\n",
    "            den += len(batch)\n",
    "    val_loss = num / den\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c063e4-fa59-487c-96a0-d9a8cf7f35f5",
   "metadata": {},
   "source": [
    "# **Read data SemEval2018-Task9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1677606e-2731-4959-a4a8-9037a69c404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd().replace('few_shot', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2344944-6187-49b1-bcb9-0f1b98c505ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackfly</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turonian</td>\n",
       "      <td>Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhorrence</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tropical storm</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>militarization</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term relation\n",
       "0        blackfly  Concept\n",
       "1        Turonian   Entity\n",
       "2      abhorrence  Concept\n",
       "3  tropical storm  Concept\n",
       "4  militarization  Concept"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_en = path+\"SemEval2018-Task9/training/data/1A.english.training.data.txt\"\n",
    "path_gold_en = path+\"SemEval2018-Task9/training/gold/1A.english.training.gold.txt\"\n",
    "\n",
    "train_data_en_data = pd.read_csv(path_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "train_gold_en_data = pd.read_csv(path_gold_en, header=None, names=['hypernym'])\n",
    "\n",
    "train_data_en_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129edda7-bf42-43e4-9fd0-7e55aa8bc714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_test_data_en = path+\"SemEval2018-Task9/test/data/1A.english.test.data.txt\"\n",
    "path_test_gold_en = path+\"SemEval2018-Task9/test/gold/1A.english.test.gold.txt\"\n",
    "\n",
    "test_data_en_data = pd.read_csv(path_test_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "test_gold_en_data = pd.read_csv(path_test_gold_en, header=None, names=['hypernym'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6b49ec1-d964-40fa-9822-e38f7c6b82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'My favorite [PARENT] is'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e5b32a-977b-448a-9738-fe533c8744ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hearest_preprocessing(train_features, train_target, test_features, test_target, hearst_pattern=pattern):\n",
    "    hearst_pattern = hearst_pattern.replace('[PARENT]', '<extra_id_0>')\n",
    "    \n",
    "    prefix = 'fill | '\n",
    "    prefix=''\n",
    "        \n",
    "    train_data_en = train_features.copy()\n",
    "    train_data_en = prefix + hearst_pattern + ' ' + train_data_en_data.term +  ' </s>'\n",
    "    print(train_data_en.head())\n",
    "\n",
    "    train_gold_en = train_target.copy()\n",
    "    train_gold_en = train_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(train_gold_en.head())\n",
    "    \n",
    "    test_data_en = test_features.copy()\n",
    "    test_data_en = prefix + hearst_pattern + ' ' + test_data_en.term +  ' </s>'\n",
    "    print(test_data_en.head())\n",
    "\n",
    "    test_gold_en = test_target.copy()\n",
    "    test_gold_en = test_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(test_gold_en.head())\n",
    "    \n",
    "    return train_data_en, train_gold_en, test_data_en, test_gold_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06205c30-fb3a-455a-b19b-93aa91cb45ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          My favorite <extra_id_0> is blackfly </s>\n",
      "1          My favorite <extra_id_0> is Turonian </s>\n",
      "2        My favorite <extra_id_0> is abhorrence </s>\n",
      "3    My favorite <extra_id_0> is tropical storm </s>\n",
      "4    My favorite <extra_id_0> is militarization </s>\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    My favorite <extra_id_0> is maliciousness </s>\n",
      "1          My favorite <extra_id_0> is buckler </s>\n",
      "2        My favorite <extra_id_0> is spelunker </s>\n",
      "3     My favorite <extra_id_0> is quo warranto </s>\n",
      "4     My favorite <extra_id_0> is Jeff Francis </s>\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data_en, train_gold_en, test_data_en, test_gold_en = hearest_preprocessing(train_data_en_data, \n",
    "                                                                                 train_gold_en_data, \n",
    "                                                                                 test_data_en_data, \n",
    "                                                                                 test_gold_en_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49168949-45b3-4f3e-952f-0c580caa0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter(output, end_token='<extra_id_1>'):\n",
    "        # The first token is <unk> (inidex at 0) and the second token is <extra_id_0> (indexed at 32099)\n",
    "        _txt = tokenizer.decode(output[2:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "        if end_token in _txt:\n",
    "            _end_token_index = _txt.index(end_token)\n",
    "            return _txt[:_end_token_index]\n",
    "        else:\n",
    "            return _txt\n",
    "\n",
    "        \n",
    "def predict_token(text):\n",
    "    \n",
    "    encoded = tokenizer.encode_plus(text, add_special_tokens=False, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "\n",
    "    # Generaing 20 sequences with maximum length set to 10\n",
    "    outputs = model.generate(input_ids=input_ids, \n",
    "                              num_beams=20, \n",
    "                              num_return_sequences=20,\n",
    "                              max_length=10)\n",
    "\n",
    "    _0_index = text.index('<extra_id_0>')\n",
    "    _result_prefix = text[:_0_index]\n",
    "    _result_suffix = text[_0_index+12:]  # 12 is the length of <extra_id_0>\n",
    "    \n",
    "    results = list(map(_filter, outputs))\n",
    "    results = [test_string.replace(',' , '')for test_string in results]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_sample(train_data_en, train_gold_en):\n",
    "    indexes = np.random.randint(0, len(train_gold_en), size=3)\n",
    "\n",
    "    selected_hypernyms = train_gold_en[indexes].str.split(', ').tolist()\n",
    "    random_selected_hypernym = [np.random.choice(target_hypernym) for target_hypernym in selected_hypernyms]\n",
    "    \n",
    "    random_selected_samples = train_data_en[indexes].str.replace('</s>', '').tolist()\n",
    "\n",
    "    return [sample.replace('<extra_id_0>', target_sample) for sample, target_sample in zip(random_selected_samples, \n",
    "                                                                                    random_selected_hypernym)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30f21ebe-8f79-4559-a0a0-0f56729ea89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My favorite granular material is greensand ',\n",
       " 'My favorite person is Sam Rainsy ',\n",
       " 'My favorite person is Kathryn Werdegar ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample(train_data_en, train_gold_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ec7d61-4b1d-4244-8164-17248857ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data_en, test_gold_en):\n",
    "    \n",
    "#   make predictions for each hyponyms\n",
    "    test_pred_en=[]\n",
    "    for text in tqdm(test_data_en.tolist()):\n",
    "        \n",
    "#   few_shot procedure\n",
    "\n",
    "        # print(text)\n",
    "        few_shot = generate_sample(train_data_en, train_gold_en)\n",
    "        few_shot.append(text)\n",
    "        text = '.\\n'.join(few_shot)\n",
    "        print(text)\n",
    "        \n",
    "        \n",
    "        # pred_masked_token = predict_token(text)\n",
    "        test_pred_en.append('\\t'.join(pred_masked_token))\n",
    "            \n",
    "#   make txt format\n",
    "    name  = 'pred_few_shot.txt'\n",
    "\n",
    "    test_pred_en_df = pd.DataFrame(test_pred_en)\n",
    "    test_pred_en_df.to_csv(name, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63a1aa33-d83a-41fe-90c1-e92787a77d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite difference of opinion is warfare .\n",
      "My favorite military rank is Richard Barnes Mason .\n",
      "My favorite pant is gabardine .\n",
      "My favorite <extra_id_0> is maliciousness </s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_masked_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_gold_en\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(test_data_en, test_gold_en)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# pred_masked_token = predict_token(text)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         test_pred_en\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mpred_masked_token\u001b[49m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#   make txt format\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     name  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_few_shot.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_masked_token' is not defined"
     ]
    }
   ],
   "source": [
    "predict(test_data_en, test_gold_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194f2130-c240-4ee7-8a6c-d92eed16776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "\n",
    "def answers(str_ans, name_of_pattern):\n",
    "    str_ans += name_of_pattern\n",
    "    columns_name = []\n",
    "    values = []\n",
    "    for ind, metrics in enumerate(_std_out.split('\\r\\n')):\n",
    "        \n",
    "        if ind == 6:\n",
    "            _name = 'number of samples in few-shot'\n",
    "            number = name_of_pattern\n",
    "        else:\n",
    "            _name, number = metrics.split(' ')\n",
    "            number = round(float(number), 5)\n",
    "            _name = _name[:-1]\n",
    "        \n",
    "        columns_name.append(_name)\n",
    "        values.append([number])\n",
    "        \n",
    "    \n",
    "        \n",
    "    df = pd.DataFrame(values).T\n",
    "    df.columns = columns_name\n",
    "    df.set_index('number of samples in few-shot', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b03944-b6b3-4509-a42d-f8cf0fdae392",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea33a8e-d510-4964-9be1-96f5a0458e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56f5c8fd-173e-4b85-83c7-57e16b696f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1ee0c5-ab84-4fac-8531-7b84254ec12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 10/10 [1:20:52<00:00, 485.27s/it]\n"
     ]
    }
   ],
   "source": [
    "few_shot_table = []\n",
    "number_of_few_shots = np.round(np.linspace(1, 10, 5).tolist() + np.linspace(1, 100, 5).tolist()[1:]).astype(int)\n",
    "\n",
    "\n",
    "for _number_few_shot in tqdm(number_of_few_shots):\n",
    "    \n",
    "#   Data processing\n",
    "    train_data_en, train_gold_en, test_data_en, test_gold_en = hearest_preprocessing(train_data_en_data,\n",
    "                                                                                     train_gold_en_data, \n",
    "                                                                                     test_data_en_data, \n",
    "                                                                                     test_gold_en_data)\n",
    "#   Predict\n",
    "    predict(test_data_en, test_gold_en)\n",
    "    \n",
    "#   Metrics\n",
    "    \n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        !python /home/jovyan/work/debuged_task9-scorer.py /home/jovyan/work/SemEval2018-Task9/test/gold/1A.english.test.gold.txt pred_few_shot.txt\n",
    "\n",
    "\n",
    "    _std_out = f.getvalue()\n",
    "\n",
    "\n",
    "    _std_out = _std_out  + str(_number_few_shot)\n",
    "    \n",
    "    _table = answers(_std_out, str(_number_few_shot))\n",
    "    few_shot_table.append(_table)\n",
    "\n",
    "\n",
    "    df = pd.concat(few_shot_table)\n",
    "    df.to_csv('few_shot_result_table.csv')\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99edcbbf-2f74-43d6-abfe-4b572a15a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "def highlight_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(s.values), props, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8293d4e7-a79a-4c6a-adfd-bdafc9495b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/18661040.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_few.drop('name of hearst pattern', axis=1, inplace=True)\n",
      "/tmp/ipykernel_98/18661040.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_few['number of few_shot samples'] = 0\n"
     ]
    }
   ],
   "source": [
    "results_no_few_shot_learning = pd.read_csv('/home/jovyan/work/hearst_patterns/hearst_patterns_result_table.csv')\n",
    "\n",
    "\n",
    "mask_ = results_no_few_shot_learning['name of hearst pattern']=='My favorite [PARENT] is'\n",
    "no_few = results_no_few_shot_learning[mask_]\n",
    "\n",
    "no_few.drop('name of hearst pattern', axis=1, inplace=True)\n",
    "\n",
    "no_few['number of few_shot samples'] = 0\n",
    "no_few.set_index('number of few_shot samples', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fa5810-28b0-4dbe-b3d1-ff12ab1ead09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of few_shot samples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16482</td>\n",
       "      <td>0.08666</td>\n",
       "      <td>0.11533</td>\n",
       "      <td>0.08822</td>\n",
       "      <td>0.08459</td>\n",
       "      <td>0.08231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16003</td>\n",
       "      <td>0.08604</td>\n",
       "      <td>0.11267</td>\n",
       "      <td>0.08800</td>\n",
       "      <td>0.08550</td>\n",
       "      <td>0.08078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.17638</td>\n",
       "      <td>0.09367</td>\n",
       "      <td>0.12667</td>\n",
       "      <td>0.09667</td>\n",
       "      <td>0.09104</td>\n",
       "      <td>0.08855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.16208</td>\n",
       "      <td>0.08656</td>\n",
       "      <td>0.10867</td>\n",
       "      <td>0.08778</td>\n",
       "      <td>0.08652</td>\n",
       "      <td>0.08280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.16923</td>\n",
       "      <td>0.08901</td>\n",
       "      <td>0.11267</td>\n",
       "      <td>0.09167</td>\n",
       "      <td>0.08686</td>\n",
       "      <td>0.08476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.15929</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.11533</td>\n",
       "      <td>0.08556</td>\n",
       "      <td>0.07822</td>\n",
       "      <td>0.07541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.16053</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.10867</td>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.08684</td>\n",
       "      <td>0.08510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.16932</td>\n",
       "      <td>0.09111</td>\n",
       "      <td>0.11733</td>\n",
       "      <td>0.09544</td>\n",
       "      <td>0.09151</td>\n",
       "      <td>0.08539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.16583</td>\n",
       "      <td>0.08824</td>\n",
       "      <td>0.11533</td>\n",
       "      <td>0.09000</td>\n",
       "      <td>0.08759</td>\n",
       "      <td>0.08376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                MRR      MAP      P@1      P@3      P@5  \\\n",
       "number of few_shot samples                                                \n",
       "1                           0.16482  0.08666  0.11533  0.08822  0.08459   \n",
       "3                           0.16003  0.08604  0.11267  0.08800  0.08550   \n",
       "6                           0.17638  0.09367  0.12667  0.09667  0.09104   \n",
       "8                           0.16208  0.08656  0.10867  0.08778  0.08652   \n",
       "10                          0.16923  0.08901  0.11267  0.09167  0.08686   \n",
       "26                          0.15929  0.08108  0.11533  0.08556  0.07822   \n",
       "50                          0.16053  0.08811  0.10867  0.08900  0.08684   \n",
       "75                          0.16932  0.09111  0.11733  0.09544  0.09151   \n",
       "100                         0.16583  0.08824  0.11533  0.09000  0.08759   \n",
       "\n",
       "                               P@15  \n",
       "number of few_shot samples           \n",
       "1                           0.08231  \n",
       "3                           0.08078  \n",
       "6                           0.08855  \n",
       "8                           0.08280  \n",
       "10                          0.08476  \n",
       "26                          0.07541  \n",
       "50                          0.08510  \n",
       "75                          0.08539  \n",
       "100                         0.08376  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9270e37-a8af-45d1-a663-70b94380d84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e93c_row0_col0, #T_6e93c_row0_col1, #T_6e93c_row0_col4, #T_6e93c_row0_col5, #T_6e93c_row3_col2, #T_6e93c_row3_col3 {\n",
       "  color: white;\n",
       "  background-color: #1FC29D;\n",
       "}\n",
       "#T_6e93c_row4_col2, #T_6e93c_row6_col0, #T_6e93c_row6_col1, #T_6e93c_row6_col3, #T_6e93c_row6_col4, #T_6e93c_row6_col5, #T_6e93c_row7_col2 {\n",
       "  color: white;\n",
       "  background-color: #FF5555;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e93c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e93c_level0_col0\" class=\"col_heading level0 col0\" >MRR</th>\n",
       "      <th id=\"T_6e93c_level0_col1\" class=\"col_heading level0 col1\" >MAP</th>\n",
       "      <th id=\"T_6e93c_level0_col2\" class=\"col_heading level0 col2\" >P@1</th>\n",
       "      <th id=\"T_6e93c_level0_col3\" class=\"col_heading level0 col3\" >P@3</th>\n",
       "      <th id=\"T_6e93c_level0_col4\" class=\"col_heading level0 col4\" >P@5</th>\n",
       "      <th id=\"T_6e93c_level0_col5\" class=\"col_heading level0 col5\" >P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >number of few_shot samples</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6e93c_row0_col0\" class=\"data row0 col0\" >0.180120</td>\n",
       "      <td id=\"T_6e93c_row0_col1\" class=\"data row0 col1\" >0.108980</td>\n",
       "      <td id=\"T_6e93c_row0_col2\" class=\"data row0 col2\" >0.114670</td>\n",
       "      <td id=\"T_6e93c_row0_col3\" class=\"data row0 col3\" >0.095330</td>\n",
       "      <td id=\"T_6e93c_row0_col4\" class=\"data row0 col4\" >0.094000</td>\n",
       "      <td id=\"T_6e93c_row0_col5\" class=\"data row0 col5\" >0.121550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6e93c_row1_col0\" class=\"data row1 col0\" >0.164820</td>\n",
       "      <td id=\"T_6e93c_row1_col1\" class=\"data row1 col1\" >0.086660</td>\n",
       "      <td id=\"T_6e93c_row1_col2\" class=\"data row1 col2\" >0.115330</td>\n",
       "      <td id=\"T_6e93c_row1_col3\" class=\"data row1 col3\" >0.088220</td>\n",
       "      <td id=\"T_6e93c_row1_col4\" class=\"data row1 col4\" >0.084590</td>\n",
       "      <td id=\"T_6e93c_row1_col5\" class=\"data row1 col5\" >0.082310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_6e93c_row2_col0\" class=\"data row2 col0\" >0.160030</td>\n",
       "      <td id=\"T_6e93c_row2_col1\" class=\"data row2 col1\" >0.086040</td>\n",
       "      <td id=\"T_6e93c_row2_col2\" class=\"data row2 col2\" >0.112670</td>\n",
       "      <td id=\"T_6e93c_row2_col3\" class=\"data row2 col3\" >0.088000</td>\n",
       "      <td id=\"T_6e93c_row2_col4\" class=\"data row2 col4\" >0.085500</td>\n",
       "      <td id=\"T_6e93c_row2_col5\" class=\"data row2 col5\" >0.080780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "      <td id=\"T_6e93c_row3_col0\" class=\"data row3 col0\" >0.176380</td>\n",
       "      <td id=\"T_6e93c_row3_col1\" class=\"data row3 col1\" >0.093670</td>\n",
       "      <td id=\"T_6e93c_row3_col2\" class=\"data row3 col2\" >0.126670</td>\n",
       "      <td id=\"T_6e93c_row3_col3\" class=\"data row3 col3\" >0.096670</td>\n",
       "      <td id=\"T_6e93c_row3_col4\" class=\"data row3 col4\" >0.091040</td>\n",
       "      <td id=\"T_6e93c_row3_col5\" class=\"data row3 col5\" >0.088550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row4\" class=\"row_heading level0 row4\" >8</th>\n",
       "      <td id=\"T_6e93c_row4_col0\" class=\"data row4 col0\" >0.162080</td>\n",
       "      <td id=\"T_6e93c_row4_col1\" class=\"data row4 col1\" >0.086560</td>\n",
       "      <td id=\"T_6e93c_row4_col2\" class=\"data row4 col2\" >0.108670</td>\n",
       "      <td id=\"T_6e93c_row4_col3\" class=\"data row4 col3\" >0.087780</td>\n",
       "      <td id=\"T_6e93c_row4_col4\" class=\"data row4 col4\" >0.086520</td>\n",
       "      <td id=\"T_6e93c_row4_col5\" class=\"data row4 col5\" >0.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row5\" class=\"row_heading level0 row5\" >10</th>\n",
       "      <td id=\"T_6e93c_row5_col0\" class=\"data row5 col0\" >0.169230</td>\n",
       "      <td id=\"T_6e93c_row5_col1\" class=\"data row5 col1\" >0.089010</td>\n",
       "      <td id=\"T_6e93c_row5_col2\" class=\"data row5 col2\" >0.112670</td>\n",
       "      <td id=\"T_6e93c_row5_col3\" class=\"data row5 col3\" >0.091670</td>\n",
       "      <td id=\"T_6e93c_row5_col4\" class=\"data row5 col4\" >0.086860</td>\n",
       "      <td id=\"T_6e93c_row5_col5\" class=\"data row5 col5\" >0.084760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row6\" class=\"row_heading level0 row6\" >26</th>\n",
       "      <td id=\"T_6e93c_row6_col0\" class=\"data row6 col0\" >0.159290</td>\n",
       "      <td id=\"T_6e93c_row6_col1\" class=\"data row6 col1\" >0.081080</td>\n",
       "      <td id=\"T_6e93c_row6_col2\" class=\"data row6 col2\" >0.115330</td>\n",
       "      <td id=\"T_6e93c_row6_col3\" class=\"data row6 col3\" >0.085560</td>\n",
       "      <td id=\"T_6e93c_row6_col4\" class=\"data row6 col4\" >0.078220</td>\n",
       "      <td id=\"T_6e93c_row6_col5\" class=\"data row6 col5\" >0.075410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row7\" class=\"row_heading level0 row7\" >50</th>\n",
       "      <td id=\"T_6e93c_row7_col0\" class=\"data row7 col0\" >0.160530</td>\n",
       "      <td id=\"T_6e93c_row7_col1\" class=\"data row7 col1\" >0.088110</td>\n",
       "      <td id=\"T_6e93c_row7_col2\" class=\"data row7 col2\" >0.108670</td>\n",
       "      <td id=\"T_6e93c_row7_col3\" class=\"data row7 col3\" >0.089000</td>\n",
       "      <td id=\"T_6e93c_row7_col4\" class=\"data row7 col4\" >0.086840</td>\n",
       "      <td id=\"T_6e93c_row7_col5\" class=\"data row7 col5\" >0.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row8\" class=\"row_heading level0 row8\" >75</th>\n",
       "      <td id=\"T_6e93c_row8_col0\" class=\"data row8 col0\" >0.169320</td>\n",
       "      <td id=\"T_6e93c_row8_col1\" class=\"data row8 col1\" >0.091110</td>\n",
       "      <td id=\"T_6e93c_row8_col2\" class=\"data row8 col2\" >0.117330</td>\n",
       "      <td id=\"T_6e93c_row8_col3\" class=\"data row8 col3\" >0.095440</td>\n",
       "      <td id=\"T_6e93c_row8_col4\" class=\"data row8 col4\" >0.091510</td>\n",
       "      <td id=\"T_6e93c_row8_col5\" class=\"data row8 col5\" >0.085390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row9\" class=\"row_heading level0 row9\" >100</th>\n",
       "      <td id=\"T_6e93c_row9_col0\" class=\"data row9 col0\" >0.165830</td>\n",
       "      <td id=\"T_6e93c_row9_col1\" class=\"data row9 col1\" >0.088240</td>\n",
       "      <td id=\"T_6e93c_row9_col2\" class=\"data row9 col2\" >0.115330</td>\n",
       "      <td id=\"T_6e93c_row9_col3\" class=\"data row9 col3\" >0.090000</td>\n",
       "      <td id=\"T_6e93c_row9_col4\" class=\"data row9 col4\" >0.087590</td>\n",
       "      <td id=\"T_6e93c_row9_col5\" class=\"data row9 col5\" >0.083760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f72247b1c60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_csv('few_shot_result_table.csv', index_col='number of few_shot samples')\n",
    "\n",
    "\n",
    "metrics = pd.concat([no_few, metrics])\n",
    "\n",
    "\n",
    "\n",
    "metrics_table = metrics.style.apply(highlight_max, props='color:white; background-color:#1FC29D', axis=0).apply(highlight_min, props='color:white; background-color:#FF5555', axis=0)\n",
    "metrics_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
