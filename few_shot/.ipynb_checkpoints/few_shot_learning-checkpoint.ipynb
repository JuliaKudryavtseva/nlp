{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4946738-b2f4-498b-b3e1-5232b71a9504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 17:19:51 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "|  0%   32C    P8    25W / 460W |   2609MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    14W / 260W |   9065MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    10W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "|  0%   31C    P8    19W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  Off |\n",
      "|  0%   35C    P8    29W / 460W |   4409MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    26W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6cc31c-642d-428e-94d7-8c41519c57fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.10.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Collecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (66.1.1)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93582 sha256=5c855245b720ed4d099dfc404182c102e6fc00edbd98d8af86f90d21b0cba79c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e5/7f/66/8bfd6d52625bf85b29fa507f79fbc3f5cb4bb72eae40318074\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.26.1 filelock-3.10.4 lit-16.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.10.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.3.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.6/769.6 kB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Installing collected packages: tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.3 regex-2023.3.23 tokenizers-0.13.2 transformers-4.27.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6b35a9-023c-4ff8-8739-bc978c1a4be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.file_utils import cached_property\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a913f3-d530-4177-b1a6-97a87397db80",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c794ce50-1061-4dd8-b3df-a0dd720f1b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from get_cuda_device import _get_cuda_command\n",
    "import os\n",
    "\n",
    "get_cuda_command('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48335c5e-32a5-464c-b95e-5e85643629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09126e4-5e03-483d-8963-33a2ae3dc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 17:21:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "|  0%   32C    P8    26W / 460W |   2609MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    14W / 260W |   9065MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8     9W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "|  0%   31C    P8    18W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  Off |\n",
      "|  0%   35C    P8    29W / 460W |   4409MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    25W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a26c278-e3ee-4084-97f6-dac02ab584b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "    print('GPU')\n",
    "else:\n",
    "    device='cpu'\n",
    "    print('CPU')\n",
    "    \n",
    "    \n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec73cecd-abb8-4635-a184-430959e38258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6d1dcbd47c4f7a9ef82071023122d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2330478b1c4d58969e3b6fe285c388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987d8fdae2a5476ea9b25c1ca2b34644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896d853582294a9d801941a3afb406bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d542829d9a42c0a18936bc583d006c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_checkpoint = \"t5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3171f4cc-6472-4797-883e-2cb95c4d0c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx <= len(self.x['input_ids']), (idx, len(self.x['input_ids']))\n",
    "        item = {key: val[idx] for key, val in self.x.items()}\n",
    "        item['decoder_attention_mask'] = self.y['attention_mask'][idx]\n",
    "        item['labels'] = self.y['input_ids'][idx]\n",
    "        return item\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.x['input_ids'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b3137b-4300-4c74-9822-6aaefce55e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "        )\n",
    "        ybatch = self.tokenizer.pad(\n",
    "            {'input_ids': batch['labels'], 'attention_mask': batch['decoder_attention_mask']},\n",
    "            padding=True,\n",
    "        ) \n",
    "        batch['labels'] = ybatch['input_ids']\n",
    "        batch['decoder_attention_mask'] = ybatch['attention_mask']\n",
    "        \n",
    "        return {k: torch.tensor(v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef1229c-d458-413c-acc9-2fb0221248b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce916472-8e8c-4436-8028-9fc1ec6ac61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            loss = model(**{k: v.to(model.device) for k, v in batch.items()}).loss\n",
    "            num += len(batch) * loss.item()\n",
    "            den += len(batch)\n",
    "    val_loss = num / den\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c063e4-fa59-487c-96a0-d9a8cf7f35f5",
   "metadata": {},
   "source": [
    "# **Read data SemEval2018-Task9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1677606e-2731-4959-a4a8-9037a69c404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd().replace('few_shot', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2344944-6187-49b1-bcb9-0f1b98c505ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackfly</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turonian</td>\n",
       "      <td>Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhorrence</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tropical storm</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>militarization</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term relation\n",
       "0        blackfly  Concept\n",
       "1        Turonian   Entity\n",
       "2      abhorrence  Concept\n",
       "3  tropical storm  Concept\n",
       "4  militarization  Concept"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_en = path+\"SemEval2018-Task9/training/data/1A.english.training.data.txt\"\n",
    "path_gold_en = path+\"SemEval2018-Task9/training/gold/1A.english.training.gold.txt\"\n",
    "\n",
    "train_data_en_data = pd.read_csv(path_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "train_gold_en_data = pd.read_csv(path_gold_en, header=None, names=['hypernym'])\n",
    "\n",
    "train_data_en_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "129edda7-bf42-43e4-9fd0-7e55aa8bc714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_test_data_en = path+\"SemEval2018-Task9/test/data/1A.english.test.data.txt\"\n",
    "path_test_gold_en = path+\"SemEval2018-Task9/test/gold/1A.english.test.gold.txt\"\n",
    "\n",
    "test_data_en_data = pd.read_csv(path_test_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "test_gold_en_data = pd.read_csv(path_test_gold_en, header=None, names=['hypernym'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6b49ec1-d964-40fa-9822-e38f7c6b82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'My favorite [PARENT] is'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e5b32a-977b-448a-9738-fe533c8744ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hearest_preprocessing(train_features, train_target, test_features, test_target, hearst_pattern=pattern):\n",
    "    hearst_pattern = hearst_pattern.replace('[PARENT]', '<extra_id_0>')\n",
    "    \n",
    "    prefix = 'fill | '\n",
    "    prefix=''\n",
    "        \n",
    "    train_data_en = train_features.copy()\n",
    "    train_data_en = prefix + hearst_pattern + ' ' + train_data_en_data.term +  ' </s>'\n",
    "    print(train_data_en.head())\n",
    "\n",
    "    train_gold_en = train_target.copy()\n",
    "    train_gold_en = train_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(train_gold_en.head())\n",
    "    \n",
    "    test_data_en = test_features.copy()\n",
    "    test_data_en = prefix + hearst_pattern + ' ' + test_data_en.term +  ' </s>'\n",
    "    print(test_data_en.head())\n",
    "\n",
    "    test_gold_en = test_target.copy()\n",
    "    test_gold_en = test_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(test_gold_en.head())\n",
    "    \n",
    "    return train_data_en, train_gold_en, test_data_en, test_gold_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06205c30-fb3a-455a-b19b-93aa91cb45ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          My favorite <extra_id_0> is blackfly </s>\n",
      "1          My favorite <extra_id_0> is Turonian </s>\n",
      "2        My favorite <extra_id_0> is abhorrence </s>\n",
      "3    My favorite <extra_id_0> is tropical storm </s>\n",
      "4    My favorite <extra_id_0> is militarization </s>\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    My favorite <extra_id_0> is maliciousness </s>\n",
      "1          My favorite <extra_id_0> is buckler </s>\n",
      "2        My favorite <extra_id_0> is spelunker </s>\n",
      "3     My favorite <extra_id_0> is quo warranto </s>\n",
      "4     My favorite <extra_id_0> is Jeff Francis </s>\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data_en, train_gold_en, test_data_en, test_gold_en = hearest_preprocessing(train_data_en_data, \n",
    "                                                                                 train_gold_en_data, \n",
    "                                                                                 test_data_en_data, \n",
    "                                                                                 test_gold_en_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49168949-45b3-4f3e-952f-0c580caa0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter(output, end_token='<extra_id_1>'):\n",
    "        # The first token is <unk> (inidex at 0) and the second token is <extra_id_0> (indexed at 32099)\n",
    "        _txt = tokenizer.decode(output[2:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "        if end_token in _txt:\n",
    "            _end_token_index = _txt.index(end_token)\n",
    "            return _txt[:_end_token_index]\n",
    "        else:\n",
    "            return _txt\n",
    "\n",
    "        \n",
    "def predict_token(text):\n",
    "    \n",
    "    encoded = tokenizer.encode_plus(text, add_special_tokens=False, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "\n",
    "    # Generaing 20 sequences with maximum length set to 10\n",
    "    outputs = model.generate(input_ids=input_ids, \n",
    "                              num_beams=20, \n",
    "                              num_return_sequences=20,\n",
    "                              max_length=10)\n",
    "\n",
    "    _0_index = text.index('<extra_id_0>')\n",
    "    _result_prefix = text[:_0_index]\n",
    "    _result_suffix = text[_0_index+12:]  # 12 is the length of <extra_id_0>\n",
    "    \n",
    "    results = list(map(_filter, outputs))\n",
    "    results = [test_string.replace(',' , '')for test_string in results]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_sample(train_data_en, train_gold_en):\n",
    "    indexes = np.random.randint(0, len(train_gold_en), size=3)\n",
    "\n",
    "    selected_hypernyms = train_gold_en[indexes].str.split(', ').tolist()\n",
    "    random_selected_hypernym = [np.random.choice(target_hypernym) for target_hypernym in selected_hypernyms]\n",
    "    \n",
    "    random_selected_samples = train_data_en[indexes].str.replace('</s>', '').tolist()\n",
    "\n",
    "    return [sample.replace('<extra_id_0>', target_sample) for sample, target_sample in zip(random_selected_samples, \n",
    "                                                                                    random_selected_hypernym)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ec7d61-4b1d-4244-8164-17248857ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data_en, test_gold_en):\n",
    "    \n",
    "#   make predictions for each hyponyms\n",
    "    test_pred_en=[]\n",
    "    for text in tqdm(test_data_en.tolist()):\n",
    "        \n",
    "#   few_shot procedure\n",
    "        few_shot = generate_sample(train_data_en, train_gold_en)\n",
    "        few_shot.append(text)\n",
    "        text = '\\t'.join(few_shot)\n",
    "        \n",
    "        \n",
    "        pred_masked_token = predict_token(text)\n",
    "        test_pred_en.append('\\t'.join(pred_masked_token))\n",
    "            \n",
    "#   make txt format\n",
    "    name  = 'pred_few_shot.txt'\n",
    "\n",
    "    test_pred_en_df = pd.DataFrame(test_pred_en)\n",
    "    test_pred_en_df.to_csv(name, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194f2130-c240-4ee7-8a6c-d92eed16776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "\n",
    "def answers(str_ans, name_of_pattern):\n",
    "    str_ans += name_of_pattern\n",
    "    columns_name = []\n",
    "    values = []\n",
    "    for ind, metrics in enumerate(_std_out.split('\\r\\n')):\n",
    "        \n",
    "        if ind == 6:\n",
    "            _name = 'number of samples in few-shot'\n",
    "            number = name_of_pattern\n",
    "        else:\n",
    "            _name, number = metrics.split(' ')\n",
    "            number = round(float(number), 5)\n",
    "            _name = _name[:-1]\n",
    "        \n",
    "        columns_name.append(_name)\n",
    "        values.append([number])\n",
    "        \n",
    "    \n",
    "        \n",
    "    df = pd.DataFrame(values).T\n",
    "    df.columns = columns_name\n",
    "    df.set_index('number of samples in few-shot', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b03944-b6b3-4509-a42d-f8cf0fdae392",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea33a8e-d510-4964-9be1-96f5a0458e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56f5c8fd-173e-4b85-83c7-57e16b696f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1ee0c5-ab84-4fac-8531-7b84254ec12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 10/10 [1:20:52<00:00, 485.27s/it]\n"
     ]
    }
   ],
   "source": [
    "few_shot_table = []\n",
    "number_of_few_shots = np.round(np.linspace(1, 10, 5).tolist() + np.linspace(1, 100, 5).tolist()[1:]).astype(int)\n",
    "\n",
    "\n",
    "for _number_few_shot in tqdm(number_of_few_shots):\n",
    "    \n",
    "#   Data processing\n",
    "    train_data_en, train_gold_en, test_data_en, test_gold_en = hearest_preprocessing(train_data_en_data,\n",
    "                                                                                     train_gold_en_data, \n",
    "                                                                                     test_data_en_data, \n",
    "                                                                                     test_gold_en_data)\n",
    "#   Predict\n",
    "    predict(test_data_en, test_gold_en)\n",
    "    \n",
    "#   Metrics\n",
    "    \n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        !python /home/jovyan/work/debuged_task9-scorer.py /home/jovyan/work/SemEval2018-Task9/test/gold/1A.english.test.gold.txt pred_few_shot.txt\n",
    "\n",
    "\n",
    "    _std_out = f.getvalue()\n",
    "\n",
    "\n",
    "    _std_out = _std_out  + str(_number_few_shot)\n",
    "    \n",
    "    _table = answers(_std_out, str(_number_few_shot))\n",
    "    few_shot_table.append(_table)\n",
    "\n",
    "\n",
    "    df = pd.concat(few_shot_table)\n",
    "    df.to_csv('few_shot_result_table.csv')\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99edcbbf-2f74-43d6-abfe-4b572a15a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "def highlight_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(s.values), props, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8293d4e7-a79a-4c6a-adfd-bdafc9495b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/18661040.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_few.drop('name of hearst pattern', axis=1, inplace=True)\n",
      "/tmp/ipykernel_98/18661040.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_few['number of few_shot samples'] = 0\n"
     ]
    }
   ],
   "source": [
    "results_no_few_shot_learning = pd.read_csv('/home/jovyan/work/hearst_patterns/hearst_patterns_result_table.csv')\n",
    "\n",
    "\n",
    "mask_ = results_no_few_shot_learning['name of hearst pattern']=='My favorite [PARENT] is'\n",
    "no_few = results_no_few_shot_learning[mask_]\n",
    "\n",
    "no_few.drop('name of hearst pattern', axis=1, inplace=True)\n",
    "\n",
    "no_few['number of few_shot samples'] = 0\n",
    "no_few.set_index('number of few_shot samples', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fa5810-28b0-4dbe-b3d1-ff12ab1ead09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of few_shot samples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16482</td>\n",
       "      <td>0.08666</td>\n",
       "      <td>0.11533</td>\n",
       "      <td>0.08822</td>\n",
       "      <td>0.08459</td>\n",
       "      <td>0.08231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16003</td>\n",
       "      <td>0.08604</td>\n",
       "      <td>0.11267</td>\n",
       "      <td>0.08800</td>\n",
       "      <td>0.08550</td>\n",
       "      <td>0.08078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.17638</td>\n",
       "      <td>0.09367</td>\n",
       "      <td>0.12667</td>\n",
       "      <td>0.09667</td>\n",
       "      <td>0.09104</td>\n",
       "      <td>0.08855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.16208</td>\n",
       "      <td>0.08656</td>\n",
       "      <td>0.10867</td>\n",
       "      <td>0.08778</td>\n",
       "      <td>0.08652</td>\n",
       "      <td>0.08280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.16923</td>\n",
       "      <td>0.08901</td>\n",
       "      <td>0.11267</td>\n",
       "      <td>0.09167</td>\n",
       "      <td>0.08686</td>\n",
       "      <td>0.08476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.15929</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.11533</td>\n",
       "      <td>0.08556</td>\n",
       "      <td>0.07822</td>\n",
       "      <td>0.07541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.16053</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.10867</td>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.08684</td>\n",
       "      <td>0.08510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.16932</td>\n",
       "      <td>0.09111</td>\n",
       "      <td>0.11733</td>\n",
       "      <td>0.09544</td>\n",
       "      <td>0.09151</td>\n",
       "      <td>0.08539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.16583</td>\n",
       "      <td>0.08824</td>\n",
       "      <td>0.11533</td>\n",
       "      <td>0.09000</td>\n",
       "      <td>0.08759</td>\n",
       "      <td>0.08376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                MRR      MAP      P@1      P@3      P@5  \\\n",
       "number of few_shot samples                                                \n",
       "1                           0.16482  0.08666  0.11533  0.08822  0.08459   \n",
       "3                           0.16003  0.08604  0.11267  0.08800  0.08550   \n",
       "6                           0.17638  0.09367  0.12667  0.09667  0.09104   \n",
       "8                           0.16208  0.08656  0.10867  0.08778  0.08652   \n",
       "10                          0.16923  0.08901  0.11267  0.09167  0.08686   \n",
       "26                          0.15929  0.08108  0.11533  0.08556  0.07822   \n",
       "50                          0.16053  0.08811  0.10867  0.08900  0.08684   \n",
       "75                          0.16932  0.09111  0.11733  0.09544  0.09151   \n",
       "100                         0.16583  0.08824  0.11533  0.09000  0.08759   \n",
       "\n",
       "                               P@15  \n",
       "number of few_shot samples           \n",
       "1                           0.08231  \n",
       "3                           0.08078  \n",
       "6                           0.08855  \n",
       "8                           0.08280  \n",
       "10                          0.08476  \n",
       "26                          0.07541  \n",
       "50                          0.08510  \n",
       "75                          0.08539  \n",
       "100                         0.08376  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9270e37-a8af-45d1-a663-70b94380d84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e93c_row0_col0, #T_6e93c_row0_col1, #T_6e93c_row0_col4, #T_6e93c_row0_col5, #T_6e93c_row3_col2, #T_6e93c_row3_col3 {\n",
       "  color: white;\n",
       "  background-color: #1FC29D;\n",
       "}\n",
       "#T_6e93c_row4_col2, #T_6e93c_row6_col0, #T_6e93c_row6_col1, #T_6e93c_row6_col3, #T_6e93c_row6_col4, #T_6e93c_row6_col5, #T_6e93c_row7_col2 {\n",
       "  color: white;\n",
       "  background-color: #FF5555;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e93c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e93c_level0_col0\" class=\"col_heading level0 col0\" >MRR</th>\n",
       "      <th id=\"T_6e93c_level0_col1\" class=\"col_heading level0 col1\" >MAP</th>\n",
       "      <th id=\"T_6e93c_level0_col2\" class=\"col_heading level0 col2\" >P@1</th>\n",
       "      <th id=\"T_6e93c_level0_col3\" class=\"col_heading level0 col3\" >P@3</th>\n",
       "      <th id=\"T_6e93c_level0_col4\" class=\"col_heading level0 col4\" >P@5</th>\n",
       "      <th id=\"T_6e93c_level0_col5\" class=\"col_heading level0 col5\" >P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >number of few_shot samples</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6e93c_row0_col0\" class=\"data row0 col0\" >0.180120</td>\n",
       "      <td id=\"T_6e93c_row0_col1\" class=\"data row0 col1\" >0.108980</td>\n",
       "      <td id=\"T_6e93c_row0_col2\" class=\"data row0 col2\" >0.114670</td>\n",
       "      <td id=\"T_6e93c_row0_col3\" class=\"data row0 col3\" >0.095330</td>\n",
       "      <td id=\"T_6e93c_row0_col4\" class=\"data row0 col4\" >0.094000</td>\n",
       "      <td id=\"T_6e93c_row0_col5\" class=\"data row0 col5\" >0.121550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6e93c_row1_col0\" class=\"data row1 col0\" >0.164820</td>\n",
       "      <td id=\"T_6e93c_row1_col1\" class=\"data row1 col1\" >0.086660</td>\n",
       "      <td id=\"T_6e93c_row1_col2\" class=\"data row1 col2\" >0.115330</td>\n",
       "      <td id=\"T_6e93c_row1_col3\" class=\"data row1 col3\" >0.088220</td>\n",
       "      <td id=\"T_6e93c_row1_col4\" class=\"data row1 col4\" >0.084590</td>\n",
       "      <td id=\"T_6e93c_row1_col5\" class=\"data row1 col5\" >0.082310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_6e93c_row2_col0\" class=\"data row2 col0\" >0.160030</td>\n",
       "      <td id=\"T_6e93c_row2_col1\" class=\"data row2 col1\" >0.086040</td>\n",
       "      <td id=\"T_6e93c_row2_col2\" class=\"data row2 col2\" >0.112670</td>\n",
       "      <td id=\"T_6e93c_row2_col3\" class=\"data row2 col3\" >0.088000</td>\n",
       "      <td id=\"T_6e93c_row2_col4\" class=\"data row2 col4\" >0.085500</td>\n",
       "      <td id=\"T_6e93c_row2_col5\" class=\"data row2 col5\" >0.080780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "      <td id=\"T_6e93c_row3_col0\" class=\"data row3 col0\" >0.176380</td>\n",
       "      <td id=\"T_6e93c_row3_col1\" class=\"data row3 col1\" >0.093670</td>\n",
       "      <td id=\"T_6e93c_row3_col2\" class=\"data row3 col2\" >0.126670</td>\n",
       "      <td id=\"T_6e93c_row3_col3\" class=\"data row3 col3\" >0.096670</td>\n",
       "      <td id=\"T_6e93c_row3_col4\" class=\"data row3 col4\" >0.091040</td>\n",
       "      <td id=\"T_6e93c_row3_col5\" class=\"data row3 col5\" >0.088550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row4\" class=\"row_heading level0 row4\" >8</th>\n",
       "      <td id=\"T_6e93c_row4_col0\" class=\"data row4 col0\" >0.162080</td>\n",
       "      <td id=\"T_6e93c_row4_col1\" class=\"data row4 col1\" >0.086560</td>\n",
       "      <td id=\"T_6e93c_row4_col2\" class=\"data row4 col2\" >0.108670</td>\n",
       "      <td id=\"T_6e93c_row4_col3\" class=\"data row4 col3\" >0.087780</td>\n",
       "      <td id=\"T_6e93c_row4_col4\" class=\"data row4 col4\" >0.086520</td>\n",
       "      <td id=\"T_6e93c_row4_col5\" class=\"data row4 col5\" >0.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row5\" class=\"row_heading level0 row5\" >10</th>\n",
       "      <td id=\"T_6e93c_row5_col0\" class=\"data row5 col0\" >0.169230</td>\n",
       "      <td id=\"T_6e93c_row5_col1\" class=\"data row5 col1\" >0.089010</td>\n",
       "      <td id=\"T_6e93c_row5_col2\" class=\"data row5 col2\" >0.112670</td>\n",
       "      <td id=\"T_6e93c_row5_col3\" class=\"data row5 col3\" >0.091670</td>\n",
       "      <td id=\"T_6e93c_row5_col4\" class=\"data row5 col4\" >0.086860</td>\n",
       "      <td id=\"T_6e93c_row5_col5\" class=\"data row5 col5\" >0.084760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row6\" class=\"row_heading level0 row6\" >26</th>\n",
       "      <td id=\"T_6e93c_row6_col0\" class=\"data row6 col0\" >0.159290</td>\n",
       "      <td id=\"T_6e93c_row6_col1\" class=\"data row6 col1\" >0.081080</td>\n",
       "      <td id=\"T_6e93c_row6_col2\" class=\"data row6 col2\" >0.115330</td>\n",
       "      <td id=\"T_6e93c_row6_col3\" class=\"data row6 col3\" >0.085560</td>\n",
       "      <td id=\"T_6e93c_row6_col4\" class=\"data row6 col4\" >0.078220</td>\n",
       "      <td id=\"T_6e93c_row6_col5\" class=\"data row6 col5\" >0.075410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row7\" class=\"row_heading level0 row7\" >50</th>\n",
       "      <td id=\"T_6e93c_row7_col0\" class=\"data row7 col0\" >0.160530</td>\n",
       "      <td id=\"T_6e93c_row7_col1\" class=\"data row7 col1\" >0.088110</td>\n",
       "      <td id=\"T_6e93c_row7_col2\" class=\"data row7 col2\" >0.108670</td>\n",
       "      <td id=\"T_6e93c_row7_col3\" class=\"data row7 col3\" >0.089000</td>\n",
       "      <td id=\"T_6e93c_row7_col4\" class=\"data row7 col4\" >0.086840</td>\n",
       "      <td id=\"T_6e93c_row7_col5\" class=\"data row7 col5\" >0.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row8\" class=\"row_heading level0 row8\" >75</th>\n",
       "      <td id=\"T_6e93c_row8_col0\" class=\"data row8 col0\" >0.169320</td>\n",
       "      <td id=\"T_6e93c_row8_col1\" class=\"data row8 col1\" >0.091110</td>\n",
       "      <td id=\"T_6e93c_row8_col2\" class=\"data row8 col2\" >0.117330</td>\n",
       "      <td id=\"T_6e93c_row8_col3\" class=\"data row8 col3\" >0.095440</td>\n",
       "      <td id=\"T_6e93c_row8_col4\" class=\"data row8 col4\" >0.091510</td>\n",
       "      <td id=\"T_6e93c_row8_col5\" class=\"data row8 col5\" >0.085390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e93c_level0_row9\" class=\"row_heading level0 row9\" >100</th>\n",
       "      <td id=\"T_6e93c_row9_col0\" class=\"data row9 col0\" >0.165830</td>\n",
       "      <td id=\"T_6e93c_row9_col1\" class=\"data row9 col1\" >0.088240</td>\n",
       "      <td id=\"T_6e93c_row9_col2\" class=\"data row9 col2\" >0.115330</td>\n",
       "      <td id=\"T_6e93c_row9_col3\" class=\"data row9 col3\" >0.090000</td>\n",
       "      <td id=\"T_6e93c_row9_col4\" class=\"data row9 col4\" >0.087590</td>\n",
       "      <td id=\"T_6e93c_row9_col5\" class=\"data row9 col5\" >0.083760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f72247b1c60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_csv('few_shot_result_table.csv', index_col='number of few_shot samples')\n",
    "\n",
    "\n",
    "metrics = pd.concat([no_few, metrics])\n",
    "\n",
    "\n",
    "\n",
    "metrics_table = metrics.style.apply(highlight_max, props='color:white; background-color:#1FC29D', axis=0).apply(highlight_min, props='color:white; background-color:#FF5555', axis=0)\n",
    "metrics_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
