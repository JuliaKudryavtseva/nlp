{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4946738-b2f4-498b-b3e1-5232b71a9504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  1 15:36:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "|  0%   27C    P8    24W / 370W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e167a3bc-5f8b-4e15-8c61-d427dfdcac4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.3.2)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.9.0 huggingface-hub-0.12.1 regex-2022.10.31 tokenizers-0.13.2 transformers-4.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6b35a9-023c-4ff8-8739-bc978c1a4be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.file_utils import cached_property\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a913f3-d530-4177-b1a6-97a87397db80",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f49cbf-db6e-4ce6-addd-d1301fd93a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  1 15:38:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "|  0%   27C    P8    24W / 370W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba76c0c3-a3c0-40ea-b5f4-1b7a8ad9ac8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a26c278-e3ee-4084-97f6-dac02ab584b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda:0'\n",
    "    print('GPU')\n",
    "else:\n",
    "    device='cpu'\n",
    "    print('CPU')\n",
    "    \n",
    "    \n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec73cecd-abb8-4635-a184-430959e38258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137e5413f14948e6a6ea91d010e9f003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab211c2a6444a4bae5c84c5385c1145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99924237cf224f06b8177102555a2b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fe15494f72403e8db261a789301191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4f269cc983464fb6a1c5533787ad62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_checkpoint = \"t5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3171f4cc-6472-4797-883e-2cb95c4d0c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx <= len(self.x['input_ids']), (idx, len(self.x['input_ids']))\n",
    "        item = {key: val[idx] for key, val in self.x.items()}\n",
    "        item['decoder_attention_mask'] = self.y['attention_mask'][idx]\n",
    "        item['labels'] = self.y['input_ids'][idx]\n",
    "        return item\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.x['input_ids'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b3137b-4300-4c74-9822-6aaefce55e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "        )\n",
    "        ybatch = self.tokenizer.pad(\n",
    "            {'input_ids': batch['labels'], 'attention_mask': batch['decoder_attention_mask']},\n",
    "            padding=True,\n",
    "        ) \n",
    "        batch['labels'] = ybatch['input_ids']\n",
    "        batch['decoder_attention_mask'] = ybatch['attention_mask']\n",
    "        \n",
    "        return {k: torch.tensor(v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef1229c-d458-413c-acc9-2fb0221248b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce916472-8e8c-4436-8028-9fc1ec6ac61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            loss = model(**{k: v.to(model.device) for k, v in batch.items()}).loss\n",
    "            num += len(batch) * loss.item()\n",
    "            den += len(batch)\n",
    "    val_loss = num / den\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c063e4-fa59-487c-96a0-d9a8cf7f35f5",
   "metadata": {},
   "source": [
    "# **Read data SemEval2018-Task9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2344944-6187-49b1-bcb9-0f1b98c505ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackfly</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turonian</td>\n",
       "      <td>Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhorrence</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tropical storm</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>militarization</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term relation\n",
       "0        blackfly  Concept\n",
       "1        Turonian   Entity\n",
       "2      abhorrence  Concept\n",
       "3  tropical storm  Concept\n",
       "4  militarization  Concept"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_en = \"SemEval2018-Task9/training/data/1A.english.training.data.txt\"\n",
    "path_gold_en = \"SemEval2018-Task9/training/gold/1A.english.training.gold.txt\"\n",
    "\n",
    "train_data_en_data = pd.read_csv(path_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "train_gold_en_data = pd.read_csv(path_gold_en, header=None, names=['hypernym'])\n",
    "\n",
    "train_data_en_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129edda7-bf42-43e4-9fd0-7e55aa8bc714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_test_data_en = \"SemEval2018-Task9/test/data/1A.english.test.data.txt\"\n",
    "path_test_gold_en = \"SemEval2018-Task9/test/gold/1A.english.test.gold.txt\"\n",
    "\n",
    "test_data_en_data = pd.read_csv(path_test_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "test_gold_en_data = pd.read_csv(path_test_gold_en, header=None, names=['hypernym'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37744552-c78d-4308-8c36-a256835839ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are a lot of [PARENT] such as',\n",
       " 'There were a lot of [PARENT] such as',\n",
       " 'There are a lot of [PARENT] here such as',\n",
       " 'Other [PARENT] such as',\n",
       " 'My favorite [PARENT] is either',\n",
       " 'There were a lot of [PARENT] here such as',\n",
       " 'which includes various [PARENT] like',\n",
       " 'Other [PARENT] especially',\n",
       " 'which includes various [PARENT] such as',\n",
       " 'My favorite [PARENT] is',\n",
       " 'I know such types of [PARENT] as',\n",
       " 'I know such kinds of [PARENT] as',\n",
       " '[PARENT] such as',\n",
       " 'I know many kinds of [PARENT] for example',\n",
       " 'Other [PARENT] for example',\n",
       " '[PARENT] ndmely',\n",
       " 'I know many types of [PARENT] for example',\n",
       " '[PARENT] including',\n",
       " 'There are a lot of [PARENT] for example',\n",
       " 'which includes various [PARENT] for example',\n",
       " 'There are a lot of [PARENT] here for example',\n",
       " '[PARENT] e.g.',\n",
       " '[PARENT] like',\n",
       " '[PARENT] especially',\n",
       " '[PARENT] for example',\n",
       " '[PARENT] for instance']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hearst_patterns = \"\"\"\n",
    "There are a lot of [PARENT] such as\n",
    "\n",
    "There were a lot of [PARENT] such as\n",
    "\n",
    "There are a lot of [PARENT] here such as\n",
    "\n",
    "Other [PARENT] such as\n",
    "\n",
    "My favorite [PARENT] is either\n",
    "\n",
    "There were a lot of [PARENT] here such as\n",
    "\n",
    "which includes various [PARENT] like\n",
    "\n",
    "Other [PARENT] especially\n",
    "\n",
    "which includes various [PARENT] such as\n",
    "\n",
    "My favorite [PARENT] is\n",
    "\n",
    "I know such types of [PARENT] as\n",
    "\n",
    "I know such kinds of [PARENT] as\n",
    "\n",
    "[PARENT] such as\n",
    "\n",
    "I know many kinds of [PARENT] for example\n",
    "\n",
    "Other [PARENT] for example\n",
    "\n",
    "[PARENT] namely\n",
    "\n",
    "I know many types of [PARENT] for example\n",
    "\n",
    "[PARENT] including\n",
    "\n",
    "There are a lot of [PARENT] for example\n",
    "\n",
    "which includes various [PARENT] for example\n",
    "\n",
    "There are a lot of [PARENT] here for example\n",
    "\n",
    "[PARENT] e.g.\n",
    "\n",
    "[PARENT] like\n",
    "\n",
    "[PARENT] especially\n",
    "\n",
    "[PARENT] for example\n",
    "\n",
    "[PARENT] for instance\n",
    "\"\"\"\n",
    "\n",
    "hearst_patterns = [pattern for ind, pattern in enumerate(hearst_patterns.split('\\n')) if ind % 2 != 0]  \n",
    "hearst_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c626a99f-dcc7-44d3-b1cc-1150671d9133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hearest_preprocessing(train_features, train_target, test_features, test_target, hearst_pattern):\n",
    "    hearst_pattern = hearst_pattern.replace('[PARENT]', '<extra_id_0>')\n",
    "        \n",
    "    train_data_en = train_features.copy()\n",
    "    train_data_en = hearst_pattern + ' ' + train_data_en_data.term\n",
    "    print(train_data_en.head())\n",
    "\n",
    "    train_gold_en = train_target.copy()\n",
    "    train_gold_en = train_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(train_gold_en.head())\n",
    "    \n",
    "    test_data_en = test_features.copy()\n",
    "    test_data_en = hearst_pattern + ' ' + test_data_en.term\n",
    "    print(test_data_en.head())\n",
    "\n",
    "    test_gold_en = test_target.copy()\n",
    "    test_gold_en = test_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(test_gold_en.head())\n",
    "    \n",
    "    return train_data_en, train_gold_en, test_data_en, test_gold_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "104ea460-4fcd-44c6-85f6-44af748bc722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     There are a lot of <extra_id_0> such as blackfly\n",
      "1     There are a lot of <extra_id_0> such as Turonian\n",
      "2    There are a lot of <extra_id_0> such as abhorr...\n",
      "3    There are a lot of <extra_id_0> such as tropic...\n",
      "4    There are a lot of <extra_id_0> such as milita...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There are a lot of <extra_id_0> such as malici...\n",
      "1      There are a lot of <extra_id_0> such as buckler\n",
      "2    There are a lot of <extra_id_0> such as spelunker\n",
      "3    There are a lot of <extra_id_0> such as quo wa...\n",
      "4    There are a lot of <extra_id_0> such as Jeff F...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data_en, train_gold_en, test_data_en, test_gold_en = hearest_preprocessing(train_data_en_data, \n",
    "                                                                                 train_gold_en_data, \n",
    "                                                                                 test_data_en_data, \n",
    "                                                                                 test_gold_en_data, \n",
    "                                                                                 hearst_patterns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fad45-8557-4569-85e9-84a9c8de4d1c",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18b98665-8190-48db-9128-eaf597e80615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use only 1 time per session\n",
    "model_checkpoint = \"t5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, max_length=100, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1d24206-3655-468e-b961-964bde0bc939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  1 16:17:03 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "|  0%   30C    P2   113W / 370W |   6393MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec1fb2-d985-4533-9bf0-e6eb06f31f4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EVALUATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "94edd7e6-385b-4747-99a1-b98bba45590b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test_data_en, test_gold_en):\n",
    "    \n",
    "#   make predictions for each hyponyms\n",
    "    test_pred_en=[]\n",
    "    for i_2 in tqdm(test_data_en.tolist()):\n",
    "\n",
    "            input_ids = tokenizer.encode(i_2, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "            output_batch = model.generate(\n",
    "                input_ids.to(device), \n",
    "                no_repeat_ngram_size=2, \n",
    "                max_new_tokens=2048, \n",
    "                num_return_sequences=30,\n",
    "                num_beams=30, \n",
    "                early_stopping=True, \n",
    "                top_k=20,\n",
    "                num_beam_groups=5, \n",
    "                diversity_penalty=1.0\n",
    "            )\n",
    "\n",
    "\n",
    "            decoded_list = []\n",
    "            for outputs in output_batch:\n",
    "                decoded = tokenizer.decode(outputs, skip_special_tokens=True).split(\", \")\n",
    "                decoded_list.extend(decoded)\n",
    "\n",
    "            sorted_predicted_answer = [i[0] for i in Counter(decoded_list).most_common()]\n",
    "\n",
    "            test_pred_en.append('\\t'.join(sorted_predicted_answer))\n",
    "            \n",
    "#   make txt format\n",
    "    name  = 'pred_hearst_pattern.txt'\n",
    "\n",
    "    test_pred_en_df = pd.DataFrame(test_pred_en)\n",
    "    test_pred_en_df.to_csv(name, header=None, index=None)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71a04b19-a666-4b10-a6e4-d194ed81e261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [09:56<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 54s, sys: 1.75 s, total: 9min 56s\n",
      "Wall time: 9min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "predict(test_data_en, test_gold_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0d0537b-b9c1-452d-a98d-c24e46a69228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "\n",
    "def metrics_table_est(name_of_pattern):\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        !python debuged_task9-scorer.py SemEval2018-Task9/test/gold/1A.english.test.gold.txt pred_hearst_pattern.txt\n",
    "    _std_out = f.getvalue()\n",
    "    \n",
    "    \n",
    "    _std_out = _std_out  + name_of_pattern\n",
    "    output = answers(_std_out, name_of_pattern)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1396bcf7-12a2-4e4d-b520-1f26edbbcbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def answers(str_ans, name_of_pattern):\n",
    "    str_ans += name_of_pattern\n",
    "    columns_name = []\n",
    "    values = []\n",
    "    for ind, metrics in enumerate(_std_out.split('\\r\\n')):\n",
    "        \n",
    "        if ind == 6:\n",
    "            _name = 'name of hearst pattern'\n",
    "            number = name_of_pattern\n",
    "        else:\n",
    "            _name, number = metrics.split(' ')\n",
    "            number = round(float(number), 5)\n",
    "            _name = _name[:-1]\n",
    "        \n",
    "        columns_name.append(_name)\n",
    "        values.append([number])\n",
    "        \n",
    "    \n",
    "        \n",
    "    df = pd.DataFrame(values).T\n",
    "    df.columns = columns_name\n",
    "    df.set_index('name of hearst pattern', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "03be1639-0415-4dd9-825f-7b3e800b7117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name of hearst pattern</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>There are a lot of [PARENT] such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MRR      MAP  P@1      P@3      P@5  \\\n",
       "name of hearst pattern                                                         \n",
       "There are a lot of [PARENT] such as  0.00072  0.00036  0.0  0.00044  0.00033   \n",
       "\n",
       "                                        P@15  \n",
       "name of hearst pattern                        \n",
       "There are a lot of [PARENT] such as  0.00043  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table_est(hearst_patterns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bfee4-080a-4111-8a7c-a6bc1ec19ec6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# All hearst patterns table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "392962da-1018-4a4c-bdf0-d6a86c700f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'hearst_patterns_result_table.csv' in os.listdir():\n",
    "    df = pd.read_csv('hearst_patterns_result_table.csv')\n",
    "    last_pattern = df['name of hearst pattern'].tail(1).values[0]\n",
    "    \n",
    "    ind = hearst_patterns.index(last_pattern)\n",
    "    hearst_patterns_in_use = hearst_patterns[ind+1:]\n",
    "    \n",
    "else:\n",
    "    hearst_patterns_in_use = hearst_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5f3d08a6-0870-4a60-9d5a-297b56f660c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     There are a lot of <extra_id_0> such as blackfly\n",
      "1     There are a lot of <extra_id_0> such as Turonian\n",
      "2    There are a lot of <extra_id_0> such as abhorr...\n",
      "3    There are a lot of <extra_id_0> such as tropic...\n",
      "4    There are a lot of <extra_id_0> such as milita...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There are a lot of <extra_id_0> such as malici...\n",
      "1      There are a lot of <extra_id_0> such as buckler\n",
      "2    There are a lot of <extra_id_0> such as spelunker\n",
      "3    There are a lot of <extra_id_0> such as quo wa...\n",
      "4    There are a lot of <extra_id_0> such as Jeff F...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:58<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    There were a lot of <extra_id_0> such as blackfly\n",
      "1    There were a lot of <extra_id_0> such as Turonian\n",
      "2    There were a lot of <extra_id_0> such as abhor...\n",
      "3    There were a lot of <extra_id_0> such as tropi...\n",
      "4    There were a lot of <extra_id_0> such as milit...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There were a lot of <extra_id_0> such as malic...\n",
      "1     There were a lot of <extra_id_0> such as buckler\n",
      "2    There were a lot of <extra_id_0> such as spelu...\n",
      "3    There were a lot of <extra_id_0> such as quo w...\n",
      "4    There were a lot of <extra_id_0> such as Jeff ...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:52<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    There are a lot of <extra_id_0> here such as b...\n",
      "1    There are a lot of <extra_id_0> here such as T...\n",
      "2    There are a lot of <extra_id_0> here such as a...\n",
      "3    There are a lot of <extra_id_0> here such as t...\n",
      "4    There are a lot of <extra_id_0> here such as m...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There are a lot of <extra_id_0> here such as m...\n",
      "1    There are a lot of <extra_id_0> here such as b...\n",
      "2    There are a lot of <extra_id_0> here such as s...\n",
      "3    There are a lot of <extra_id_0> here such as q...\n",
      "4    There are a lot of <extra_id_0> here such as J...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:29<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          Other <extra_id_0> such as blackfly\n",
      "1          Other <extra_id_0> such as Turonian\n",
      "2        Other <extra_id_0> such as abhorrence\n",
      "3    Other <extra_id_0> such as tropical storm\n",
      "4    Other <extra_id_0> such as militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    Other <extra_id_0> such as maliciousness\n",
      "1          Other <extra_id_0> such as buckler\n",
      "2        Other <extra_id_0> such as spelunker\n",
      "3     Other <extra_id_0> such as quo warranto\n",
      "4     Other <extra_id_0> such as Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [09:28<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          My favorite <extra_id_0> is either blackfly\n",
      "1          My favorite <extra_id_0> is either Turonian\n",
      "2        My favorite <extra_id_0> is either abhorrence\n",
      "3    My favorite <extra_id_0> is either tropical storm\n",
      "4    My favorite <extra_id_0> is either militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    My favorite <extra_id_0> is either maliciousness\n",
      "1          My favorite <extra_id_0> is either buckler\n",
      "2        My favorite <extra_id_0> is either spelunker\n",
      "3     My favorite <extra_id_0> is either quo warranto\n",
      "4     My favorite <extra_id_0> is either Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:40<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    There were a lot of <extra_id_0> here such as ...\n",
      "1    There were a lot of <extra_id_0> here such as ...\n",
      "2    There were a lot of <extra_id_0> here such as ...\n",
      "3    There were a lot of <extra_id_0> here such as ...\n",
      "4    There were a lot of <extra_id_0> here such as ...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There were a lot of <extra_id_0> here such as ...\n",
      "1    There were a lot of <extra_id_0> here such as ...\n",
      "2    There were a lot of <extra_id_0> here such as ...\n",
      "3    There were a lot of <extra_id_0> here such as ...\n",
      "4    There were a lot of <extra_id_0> here such as ...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:22<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    which includes various <extra_id_0> like blackfly\n",
      "1    which includes various <extra_id_0> like Turonian\n",
      "2    which includes various <extra_id_0> like abhor...\n",
      "3    which includes various <extra_id_0> like tropi...\n",
      "4    which includes various <extra_id_0> like milit...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    which includes various <extra_id_0> like malic...\n",
      "1     which includes various <extra_id_0> like buckler\n",
      "2    which includes various <extra_id_0> like spelu...\n",
      "3    which includes various <extra_id_0> like quo w...\n",
      "4    which includes various <extra_id_0> like Jeff ...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:34<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          Other <extra_id_0> especially blackfly\n",
      "1          Other <extra_id_0> especially Turonian\n",
      "2        Other <extra_id_0> especially abhorrence\n",
      "3    Other <extra_id_0> especially tropical storm\n",
      "4    Other <extra_id_0> especially militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    Other <extra_id_0> especially maliciousness\n",
      "1          Other <extra_id_0> especially buckler\n",
      "2        Other <extra_id_0> especially spelunker\n",
      "3     Other <extra_id_0> especially quo warranto\n",
      "4     Other <extra_id_0> especially Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [08:29<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    which includes various <extra_id_0> such as bl...\n",
      "1    which includes various <extra_id_0> such as Tu...\n",
      "2    which includes various <extra_id_0> such as ab...\n",
      "3    which includes various <extra_id_0> such as tr...\n",
      "4    which includes various <extra_id_0> such as mi...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    which includes various <extra_id_0> such as ma...\n",
      "1    which includes various <extra_id_0> such as bu...\n",
      "2    which includes various <extra_id_0> such as sp...\n",
      "3    which includes various <extra_id_0> such as qu...\n",
      "4    which includes various <extra_id_0> such as Je...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:56<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          My favorite <extra_id_0> is blackfly\n",
      "1          My favorite <extra_id_0> is Turonian\n",
      "2        My favorite <extra_id_0> is abhorrence\n",
      "3    My favorite <extra_id_0> is tropical storm\n",
      "4    My favorite <extra_id_0> is militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    My favorite <extra_id_0> is maliciousness\n",
      "1          My favorite <extra_id_0> is buckler\n",
      "2        My favorite <extra_id_0> is spelunker\n",
      "3     My favorite <extra_id_0> is quo warranto\n",
      "4     My favorite <extra_id_0> is Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [06:51<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0        I know such types of <extra_id_0> as blackfly\n",
      "1        I know such types of <extra_id_0> as Turonian\n",
      "2      I know such types of <extra_id_0> as abhorrence\n",
      "3    I know such types of <extra_id_0> as tropical ...\n",
      "4    I know such types of <extra_id_0> as militariz...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    I know such types of <extra_id_0> as malicious...\n",
      "1         I know such types of <extra_id_0> as buckler\n",
      "2       I know such types of <extra_id_0> as spelunker\n",
      "3    I know such types of <extra_id_0> as quo warranto\n",
      "4    I know such types of <extra_id_0> as Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [06:55<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0        I know such kinds of <extra_id_0> as blackfly\n",
      "1        I know such kinds of <extra_id_0> as Turonian\n",
      "2      I know such kinds of <extra_id_0> as abhorrence\n",
      "3    I know such kinds of <extra_id_0> as tropical ...\n",
      "4    I know such kinds of <extra_id_0> as militariz...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    I know such kinds of <extra_id_0> as malicious...\n",
      "1         I know such kinds of <extra_id_0> as buckler\n",
      "2       I know such kinds of <extra_id_0> as spelunker\n",
      "3    I know such kinds of <extra_id_0> as quo warranto\n",
      "4    I know such kinds of <extra_id_0> as Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [06:58<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> such as blackfly\n",
      "1          <extra_id_0> such as Turonian\n",
      "2        <extra_id_0> such as abhorrence\n",
      "3    <extra_id_0> such as tropical storm\n",
      "4    <extra_id_0> such as militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> such as maliciousness\n",
      "1          <extra_id_0> such as buckler\n",
      "2        <extra_id_0> such as spelunker\n",
      "3     <extra_id_0> such as quo warranto\n",
      "4     <extra_id_0> such as Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [13:17<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    I know many kinds of <extra_id_0> for example ...\n",
      "1    I know many kinds of <extra_id_0> for example ...\n",
      "2    I know many kinds of <extra_id_0> for example ...\n",
      "3    I know many kinds of <extra_id_0> for example ...\n",
      "4    I know many kinds of <extra_id_0> for example ...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    I know many kinds of <extra_id_0> for example ...\n",
      "1    I know many kinds of <extra_id_0> for example ...\n",
      "2    I know many kinds of <extra_id_0> for example ...\n",
      "3    I know many kinds of <extra_id_0> for example ...\n",
      "4    I know many kinds of <extra_id_0> for example ...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:21<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          Other <extra_id_0> for example blackfly\n",
      "1          Other <extra_id_0> for example Turonian\n",
      "2        Other <extra_id_0> for example abhorrence\n",
      "3    Other <extra_id_0> for example tropical storm\n",
      "4    Other <extra_id_0> for example militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    Other <extra_id_0> for example maliciousness\n",
      "1          Other <extra_id_0> for example buckler\n",
      "2        Other <extra_id_0> for example spelunker\n",
      "3     Other <extra_id_0> for example quo warranto\n",
      "4     Other <extra_id_0> for example Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [08:20<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> ndmely blackfly\n",
      "1          <extra_id_0> ndmely Turonian\n",
      "2        <extra_id_0> ndmely abhorrence\n",
      "3    <extra_id_0> ndmely tropical storm\n",
      "4    <extra_id_0> ndmely militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> ndmely maliciousness\n",
      "1          <extra_id_0> ndmely buckler\n",
      "2        <extra_id_0> ndmely spelunker\n",
      "3     <extra_id_0> ndmely quo warranto\n",
      "4     <extra_id_0> ndmely Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [08:55<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    I know many types of <extra_id_0> for example ...\n",
      "1    I know many types of <extra_id_0> for example ...\n",
      "2    I know many types of <extra_id_0> for example ...\n",
      "3    I know many types of <extra_id_0> for example ...\n",
      "4    I know many types of <extra_id_0> for example ...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    I know many types of <extra_id_0> for example ...\n",
      "1    I know many types of <extra_id_0> for example ...\n",
      "2    I know many types of <extra_id_0> for example ...\n",
      "3    I know many types of <extra_id_0> for example ...\n",
      "4    I know many types of <extra_id_0> for example ...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:42<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> including blackfly\n",
      "1          <extra_id_0> including Turonian\n",
      "2        <extra_id_0> including abhorrence\n",
      "3    <extra_id_0> including tropical storm\n",
      "4    <extra_id_0> including militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> including maliciousness\n",
      "1          <extra_id_0> including buckler\n",
      "2        <extra_id_0> including spelunker\n",
      "3     <extra_id_0> including quo warranto\n",
      "4     <extra_id_0> including Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [12:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    There are a lot of <extra_id_0> for example bl...\n",
      "1    There are a lot of <extra_id_0> for example Tu...\n",
      "2    There are a lot of <extra_id_0> for example ab...\n",
      "3    There are a lot of <extra_id_0> for example tr...\n",
      "4    There are a lot of <extra_id_0> for example mi...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There are a lot of <extra_id_0> for example ma...\n",
      "1    There are a lot of <extra_id_0> for example bu...\n",
      "2    There are a lot of <extra_id_0> for example sp...\n",
      "3    There are a lot of <extra_id_0> for example qu...\n",
      "4    There are a lot of <extra_id_0> for example Je...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [11:15<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    which includes various <extra_id_0> for exampl...\n",
      "1    which includes various <extra_id_0> for exampl...\n",
      "2    which includes various <extra_id_0> for exampl...\n",
      "3    which includes various <extra_id_0> for exampl...\n",
      "4    which includes various <extra_id_0> for exampl...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    which includes various <extra_id_0> for exampl...\n",
      "1    which includes various <extra_id_0> for exampl...\n",
      "2    which includes various <extra_id_0> for exampl...\n",
      "3    which includes various <extra_id_0> for exampl...\n",
      "4    which includes various <extra_id_0> for exampl...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [08:22<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0    There are a lot of <extra_id_0> here for examp...\n",
      "1    There are a lot of <extra_id_0> here for examp...\n",
      "2    There are a lot of <extra_id_0> here for examp...\n",
      "3    There are a lot of <extra_id_0> here for examp...\n",
      "4    There are a lot of <extra_id_0> here for examp...\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    There are a lot of <extra_id_0> here for examp...\n",
      "1    There are a lot of <extra_id_0> here for examp...\n",
      "2    There are a lot of <extra_id_0> here for examp...\n",
      "3    There are a lot of <extra_id_0> here for examp...\n",
      "4    There are a lot of <extra_id_0> here for examp...\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [07:34<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> e.g. blackfly\n",
      "1          <extra_id_0> e.g. Turonian\n",
      "2        <extra_id_0> e.g. abhorrence\n",
      "3    <extra_id_0> e.g. tropical storm\n",
      "4    <extra_id_0> e.g. militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> e.g. maliciousness\n",
      "1          <extra_id_0> e.g. buckler\n",
      "2        <extra_id_0> e.g. spelunker\n",
      "3     <extra_id_0> e.g. quo warranto\n",
      "4     <extra_id_0> e.g. Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [06:31<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> like blackfly\n",
      "1          <extra_id_0> like Turonian\n",
      "2        <extra_id_0> like abhorrence\n",
      "3    <extra_id_0> like tropical storm\n",
      "4    <extra_id_0> like militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> like maliciousness\n",
      "1          <extra_id_0> like buckler\n",
      "2        <extra_id_0> like spelunker\n",
      "3     <extra_id_0> like quo warranto\n",
      "4     <extra_id_0> like Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [09:44<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> especially blackfly\n",
      "1          <extra_id_0> especially Turonian\n",
      "2        <extra_id_0> especially abhorrence\n",
      "3    <extra_id_0> especially tropical storm\n",
      "4    <extra_id_0> especially militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> especially maliciousness\n",
      "1          <extra_id_0> especially buckler\n",
      "2        <extra_id_0> especially spelunker\n",
      "3     <extra_id_0> especially quo warranto\n",
      "4     <extra_id_0> especially Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [08:17<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> for example blackfly\n",
      "1          <extra_id_0> for example Turonian\n",
      "2        <extra_id_0> for example abhorrence\n",
      "3    <extra_id_0> for example tropical storm\n",
      "4    <extra_id_0> for example militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> for example maliciousness\n",
      "1          <extra_id_0> for example buckler\n",
      "2        <extra_id_0> for example spelunker\n",
      "3     <extra_id_0> for example quo warranto\n",
      "4     <extra_id_0> for example Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [10:37<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0          <extra_id_0> for instance blackfly\n",
      "1          <extra_id_0> for instance Turonian\n",
      "2        <extra_id_0> for instance abhorrence\n",
      "3    <extra_id_0> for instance tropical storm\n",
      "4    <extra_id_0> for instance militarization\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    <extra_id_0> for instance maliciousness\n",
      "1          <extra_id_0> for instance buckler\n",
      "2        <extra_id_0> for instance spelunker\n",
      "3     <extra_id_0> for instance quo warranto\n",
      "4     <extra_id_0> for instance Jeff Francis\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [09:52<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "hearst_patterns_table = []\n",
    "\n",
    "for pattern in hearst_patterns_in_use:\n",
    "    \n",
    "#   Data processing\n",
    "    train_data_en, train_gold_en, test_data_en, test_gold_en = hearest_preprocessing(train_data_en_data,\n",
    "                                                                                     train_gold_en_data, \n",
    "                                                                                     test_data_en_data, \n",
    "                                                                                     test_gold_en_data, \n",
    "                                                                                     pattern)\n",
    "#   Predict\n",
    "    predict(test_data_en, test_gold_en)\n",
    "    \n",
    "    pattern_table = metrics_table_est(pattern)\n",
    "    hearst_patterns_table.append(pattern_table)\n",
    "\n",
    "#   Metrics\n",
    "    df = pd.concat(hearst_patterns_table)\n",
    "    df.to_csv('hearst_patterns_result_table.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "daa6258a-2edb-409b-8c3d-74a6a3deaf55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name of hearst pattern</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>There are a lot of [PARENT] such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There were a lot of [PARENT] such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There are a lot of [PARENT] here such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other [PARENT] such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My favorite [PARENT] is either</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There were a lot of [PARENT] here such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which includes various [PARENT] like</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other [PARENT] especially</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which includes various [PARENT] such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My favorite [PARENT] is</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I know such types of [PARENT] as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I know such kinds of [PARENT] as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] such as</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I know many kinds of [PARENT] for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other [PARENT] for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] ndmely</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I know many types of [PARENT] for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] including</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There are a lot of [PARENT] for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which includes various [PARENT] for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There are a lot of [PARENT] here for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] e.g.</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] like</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] especially</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] for example</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[PARENT] for instance</th>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  MRR      MAP  P@1      P@3  \\\n",
       "name of hearst pattern                                                         \n",
       "There are a lot of [PARENT] such as           0.00072  0.00036  0.0  0.00044   \n",
       "There were a lot of [PARENT] such as          0.00072  0.00036  0.0  0.00044   \n",
       "There are a lot of [PARENT] here such as      0.00072  0.00036  0.0  0.00044   \n",
       "Other [PARENT] such as                        0.00072  0.00036  0.0  0.00044   \n",
       "My favorite [PARENT] is either                0.00072  0.00036  0.0  0.00044   \n",
       "There were a lot of [PARENT] here such as     0.00072  0.00036  0.0  0.00044   \n",
       "which includes various [PARENT] like          0.00072  0.00036  0.0  0.00044   \n",
       "Other [PARENT] especially                     0.00072  0.00036  0.0  0.00044   \n",
       "which includes various [PARENT] such as       0.00072  0.00036  0.0  0.00044   \n",
       "My favorite [PARENT] is                       0.00072  0.00036  0.0  0.00044   \n",
       "I know such types of [PARENT] as              0.00072  0.00036  0.0  0.00044   \n",
       "I know such kinds of [PARENT] as              0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] such as                              0.00072  0.00036  0.0  0.00044   \n",
       "I know many kinds of [PARENT] for example     0.00072  0.00036  0.0  0.00044   \n",
       "Other [PARENT] for example                    0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] ndmely                               0.00072  0.00036  0.0  0.00044   \n",
       "I know many types of [PARENT] for example     0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] including                            0.00072  0.00036  0.0  0.00044   \n",
       "There are a lot of [PARENT] for example       0.00072  0.00036  0.0  0.00044   \n",
       "which includes various [PARENT] for example   0.00072  0.00036  0.0  0.00044   \n",
       "There are a lot of [PARENT] here for example  0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] e.g.                                 0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] like                                 0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] especially                           0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] for example                          0.00072  0.00036  0.0  0.00044   \n",
       "[PARENT] for instance                         0.00072  0.00036  0.0  0.00044   \n",
       "\n",
       "                                                  P@5     P@15  \n",
       "name of hearst pattern                                          \n",
       "There are a lot of [PARENT] such as           0.00033  0.00043  \n",
       "There were a lot of [PARENT] such as          0.00033  0.00043  \n",
       "There are a lot of [PARENT] here such as      0.00033  0.00043  \n",
       "Other [PARENT] such as                        0.00033  0.00043  \n",
       "My favorite [PARENT] is either                0.00033  0.00043  \n",
       "There were a lot of [PARENT] here such as     0.00033  0.00043  \n",
       "which includes various [PARENT] like          0.00033  0.00043  \n",
       "Other [PARENT] especially                     0.00033  0.00043  \n",
       "which includes various [PARENT] such as       0.00033  0.00043  \n",
       "My favorite [PARENT] is                       0.00033  0.00043  \n",
       "I know such types of [PARENT] as              0.00033  0.00043  \n",
       "I know such kinds of [PARENT] as              0.00033  0.00043  \n",
       "[PARENT] such as                              0.00033  0.00043  \n",
       "I know many kinds of [PARENT] for example     0.00033  0.00043  \n",
       "Other [PARENT] for example                    0.00033  0.00043  \n",
       "[PARENT] ndmely                               0.00033  0.00043  \n",
       "I know many types of [PARENT] for example     0.00033  0.00043  \n",
       "[PARENT] including                            0.00033  0.00043  \n",
       "There are a lot of [PARENT] for example       0.00033  0.00043  \n",
       "which includes various [PARENT] for example   0.00033  0.00043  \n",
       "There are a lot of [PARENT] here for example  0.00033  0.00043  \n",
       "[PARENT] e.g.                                 0.00033  0.00043  \n",
       "[PARENT] like                                 0.00033  0.00043  \n",
       "[PARENT] especially                           0.00033  0.00043  \n",
       "[PARENT] for example                          0.00033  0.00043  \n",
       "[PARENT] for instance                         0.00033  0.00043  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table = pd.read_csv('hearst_patterns_result_table.csv').set_index('name of hearst pattern')\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c1c2850e-83ce-4ddb-8022-7422971b908d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a0518_row0_col0, #T_a0518_row0_col1, #T_a0518_row0_col2, #T_a0518_row0_col3, #T_a0518_row0_col4, #T_a0518_row0_col5, #T_a0518_row1_col0, #T_a0518_row1_col1, #T_a0518_row1_col2, #T_a0518_row1_col3, #T_a0518_row1_col4, #T_a0518_row1_col5, #T_a0518_row2_col0, #T_a0518_row2_col1, #T_a0518_row2_col2, #T_a0518_row2_col3, #T_a0518_row2_col4, #T_a0518_row2_col5, #T_a0518_row3_col0, #T_a0518_row3_col1, #T_a0518_row3_col2, #T_a0518_row3_col3, #T_a0518_row3_col4, #T_a0518_row3_col5, #T_a0518_row4_col0, #T_a0518_row4_col1, #T_a0518_row4_col2, #T_a0518_row4_col3, #T_a0518_row4_col4, #T_a0518_row4_col5, #T_a0518_row5_col0, #T_a0518_row5_col1, #T_a0518_row5_col2, #T_a0518_row5_col3, #T_a0518_row5_col4, #T_a0518_row5_col5, #T_a0518_row6_col0, #T_a0518_row6_col1, #T_a0518_row6_col2, #T_a0518_row6_col3, #T_a0518_row6_col4, #T_a0518_row6_col5, #T_a0518_row7_col0, #T_a0518_row7_col1, #T_a0518_row7_col2, #T_a0518_row7_col3, #T_a0518_row7_col4, #T_a0518_row7_col5, #T_a0518_row8_col0, #T_a0518_row8_col1, #T_a0518_row8_col2, #T_a0518_row8_col3, #T_a0518_row8_col4, #T_a0518_row8_col5, #T_a0518_row9_col0, #T_a0518_row9_col1, #T_a0518_row9_col2, #T_a0518_row9_col3, #T_a0518_row9_col4, #T_a0518_row9_col5, #T_a0518_row10_col0, #T_a0518_row10_col1, #T_a0518_row10_col2, #T_a0518_row10_col3, #T_a0518_row10_col4, #T_a0518_row10_col5, #T_a0518_row11_col0, #T_a0518_row11_col1, #T_a0518_row11_col2, #T_a0518_row11_col3, #T_a0518_row11_col4, #T_a0518_row11_col5, #T_a0518_row12_col0, #T_a0518_row12_col1, #T_a0518_row12_col2, #T_a0518_row12_col3, #T_a0518_row12_col4, #T_a0518_row12_col5, #T_a0518_row13_col0, #T_a0518_row13_col1, #T_a0518_row13_col2, #T_a0518_row13_col3, #T_a0518_row13_col4, #T_a0518_row13_col5, #T_a0518_row14_col0, #T_a0518_row14_col1, #T_a0518_row14_col2, #T_a0518_row14_col3, #T_a0518_row14_col4, #T_a0518_row14_col5, #T_a0518_row15_col0, #T_a0518_row15_col1, #T_a0518_row15_col2, #T_a0518_row15_col3, #T_a0518_row15_col4, #T_a0518_row15_col5, #T_a0518_row16_col0, #T_a0518_row16_col1, #T_a0518_row16_col2, #T_a0518_row16_col3, #T_a0518_row16_col4, #T_a0518_row16_col5, #T_a0518_row17_col0, #T_a0518_row17_col1, #T_a0518_row17_col2, #T_a0518_row17_col3, #T_a0518_row17_col4, #T_a0518_row17_col5, #T_a0518_row18_col0, #T_a0518_row18_col1, #T_a0518_row18_col2, #T_a0518_row18_col3, #T_a0518_row18_col4, #T_a0518_row18_col5, #T_a0518_row19_col0, #T_a0518_row19_col1, #T_a0518_row19_col2, #T_a0518_row19_col3, #T_a0518_row19_col4, #T_a0518_row19_col5, #T_a0518_row20_col0, #T_a0518_row20_col1, #T_a0518_row20_col2, #T_a0518_row20_col3, #T_a0518_row20_col4, #T_a0518_row20_col5, #T_a0518_row21_col0, #T_a0518_row21_col1, #T_a0518_row21_col2, #T_a0518_row21_col3, #T_a0518_row21_col4, #T_a0518_row21_col5, #T_a0518_row22_col0, #T_a0518_row22_col1, #T_a0518_row22_col2, #T_a0518_row22_col3, #T_a0518_row22_col4, #T_a0518_row22_col5, #T_a0518_row23_col0, #T_a0518_row23_col1, #T_a0518_row23_col2, #T_a0518_row23_col3, #T_a0518_row23_col4, #T_a0518_row23_col5, #T_a0518_row24_col0, #T_a0518_row24_col1, #T_a0518_row24_col2, #T_a0518_row24_col3, #T_a0518_row24_col4, #T_a0518_row24_col5, #T_a0518_row25_col0, #T_a0518_row25_col1, #T_a0518_row25_col2, #T_a0518_row25_col3, #T_a0518_row25_col4, #T_a0518_row25_col5 {\n",
       "  color: white;\n",
       "  background-color: #1FC29D;\n",
       "  color: white;\n",
       "  background-color: #FF5555;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a0518\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a0518_level0_col0\" class=\"col_heading level0 col0\" >MRR</th>\n",
       "      <th id=\"T_a0518_level0_col1\" class=\"col_heading level0 col1\" >MAP</th>\n",
       "      <th id=\"T_a0518_level0_col2\" class=\"col_heading level0 col2\" >P@1</th>\n",
       "      <th id=\"T_a0518_level0_col3\" class=\"col_heading level0 col3\" >P@3</th>\n",
       "      <th id=\"T_a0518_level0_col4\" class=\"col_heading level0 col4\" >P@5</th>\n",
       "      <th id=\"T_a0518_level0_col5\" class=\"col_heading level0 col5\" >P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >name of hearst pattern</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row0\" class=\"row_heading level0 row0\" >There are a lot of [PARENT] such as</th>\n",
       "      <td id=\"T_a0518_row0_col0\" class=\"data row0 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row0_col1\" class=\"data row0 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row0_col3\" class=\"data row0 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row0_col4\" class=\"data row0 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row0_col5\" class=\"data row0 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row1\" class=\"row_heading level0 row1\" >There were a lot of [PARENT] such as</th>\n",
       "      <td id=\"T_a0518_row1_col0\" class=\"data row1 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row1_col1\" class=\"data row1 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row1_col3\" class=\"data row1 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row1_col4\" class=\"data row1 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row1_col5\" class=\"data row1 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row2\" class=\"row_heading level0 row2\" >There are a lot of [PARENT] here such as</th>\n",
       "      <td id=\"T_a0518_row2_col0\" class=\"data row2 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row2_col1\" class=\"data row2 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row2_col3\" class=\"data row2 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row2_col4\" class=\"data row2 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row2_col5\" class=\"data row2 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row3\" class=\"row_heading level0 row3\" >Other [PARENT] such as</th>\n",
       "      <td id=\"T_a0518_row3_col0\" class=\"data row3 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row3_col1\" class=\"data row3 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row3_col3\" class=\"data row3 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row3_col4\" class=\"data row3 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row3_col5\" class=\"data row3 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row4\" class=\"row_heading level0 row4\" >My favorite [PARENT] is either</th>\n",
       "      <td id=\"T_a0518_row4_col0\" class=\"data row4 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row4_col1\" class=\"data row4 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row4_col3\" class=\"data row4 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row4_col4\" class=\"data row4 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row4_col5\" class=\"data row4 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row5\" class=\"row_heading level0 row5\" >There were a lot of [PARENT] here such as</th>\n",
       "      <td id=\"T_a0518_row5_col0\" class=\"data row5 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row5_col1\" class=\"data row5 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row5_col3\" class=\"data row5 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row5_col4\" class=\"data row5 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row5_col5\" class=\"data row5 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row6\" class=\"row_heading level0 row6\" >which includes various [PARENT] like</th>\n",
       "      <td id=\"T_a0518_row6_col0\" class=\"data row6 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row6_col1\" class=\"data row6 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row6_col3\" class=\"data row6 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row6_col4\" class=\"data row6 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row6_col5\" class=\"data row6 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row7\" class=\"row_heading level0 row7\" >Other [PARENT] especially</th>\n",
       "      <td id=\"T_a0518_row7_col0\" class=\"data row7 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row7_col1\" class=\"data row7 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row7_col3\" class=\"data row7 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row7_col4\" class=\"data row7 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row7_col5\" class=\"data row7 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row8\" class=\"row_heading level0 row8\" >which includes various [PARENT] such as</th>\n",
       "      <td id=\"T_a0518_row8_col0\" class=\"data row8 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row8_col1\" class=\"data row8 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row8_col3\" class=\"data row8 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row8_col4\" class=\"data row8 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row8_col5\" class=\"data row8 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row9\" class=\"row_heading level0 row9\" >My favorite [PARENT] is</th>\n",
       "      <td id=\"T_a0518_row9_col0\" class=\"data row9 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row9_col1\" class=\"data row9 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row9_col3\" class=\"data row9 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row9_col4\" class=\"data row9 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row9_col5\" class=\"data row9 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row10\" class=\"row_heading level0 row10\" >I know such types of [PARENT] as</th>\n",
       "      <td id=\"T_a0518_row10_col0\" class=\"data row10 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row10_col1\" class=\"data row10 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row10_col3\" class=\"data row10 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row10_col4\" class=\"data row10 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row10_col5\" class=\"data row10 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row11\" class=\"row_heading level0 row11\" >I know such kinds of [PARENT] as</th>\n",
       "      <td id=\"T_a0518_row11_col0\" class=\"data row11 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row11_col1\" class=\"data row11 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row11_col3\" class=\"data row11 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row11_col4\" class=\"data row11 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row11_col5\" class=\"data row11 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row12\" class=\"row_heading level0 row12\" >[PARENT] such as</th>\n",
       "      <td id=\"T_a0518_row12_col0\" class=\"data row12 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row12_col1\" class=\"data row12 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row12_col3\" class=\"data row12 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row12_col4\" class=\"data row12 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row12_col5\" class=\"data row12 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row13\" class=\"row_heading level0 row13\" >I know many kinds of [PARENT] for example</th>\n",
       "      <td id=\"T_a0518_row13_col0\" class=\"data row13 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row13_col1\" class=\"data row13 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row13_col3\" class=\"data row13 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row13_col4\" class=\"data row13 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row13_col5\" class=\"data row13 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row14\" class=\"row_heading level0 row14\" >Other [PARENT] for example</th>\n",
       "      <td id=\"T_a0518_row14_col0\" class=\"data row14 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row14_col1\" class=\"data row14 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row14_col2\" class=\"data row14 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row14_col3\" class=\"data row14 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row14_col4\" class=\"data row14 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row14_col5\" class=\"data row14 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row15\" class=\"row_heading level0 row15\" >[PARENT] ndmely</th>\n",
       "      <td id=\"T_a0518_row15_col0\" class=\"data row15 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row15_col1\" class=\"data row15 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row15_col2\" class=\"data row15 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row15_col3\" class=\"data row15 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row15_col4\" class=\"data row15 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row15_col5\" class=\"data row15 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row16\" class=\"row_heading level0 row16\" >I know many types of [PARENT] for example</th>\n",
       "      <td id=\"T_a0518_row16_col0\" class=\"data row16 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row16_col1\" class=\"data row16 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row16_col2\" class=\"data row16 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row16_col3\" class=\"data row16 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row16_col4\" class=\"data row16 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row16_col5\" class=\"data row16 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row17\" class=\"row_heading level0 row17\" >[PARENT] including</th>\n",
       "      <td id=\"T_a0518_row17_col0\" class=\"data row17 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row17_col1\" class=\"data row17 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row17_col2\" class=\"data row17 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row17_col3\" class=\"data row17 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row17_col4\" class=\"data row17 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row17_col5\" class=\"data row17 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row18\" class=\"row_heading level0 row18\" >There are a lot of [PARENT] for example</th>\n",
       "      <td id=\"T_a0518_row18_col0\" class=\"data row18 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row18_col1\" class=\"data row18 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row18_col2\" class=\"data row18 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row18_col3\" class=\"data row18 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row18_col4\" class=\"data row18 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row18_col5\" class=\"data row18 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row19\" class=\"row_heading level0 row19\" >which includes various [PARENT] for example</th>\n",
       "      <td id=\"T_a0518_row19_col0\" class=\"data row19 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row19_col1\" class=\"data row19 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row19_col2\" class=\"data row19 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row19_col3\" class=\"data row19 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row19_col4\" class=\"data row19 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row19_col5\" class=\"data row19 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row20\" class=\"row_heading level0 row20\" >There are a lot of [PARENT] here for example</th>\n",
       "      <td id=\"T_a0518_row20_col0\" class=\"data row20 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row20_col1\" class=\"data row20 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row20_col2\" class=\"data row20 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row20_col3\" class=\"data row20 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row20_col4\" class=\"data row20 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row20_col5\" class=\"data row20 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row21\" class=\"row_heading level0 row21\" >[PARENT] e.g.</th>\n",
       "      <td id=\"T_a0518_row21_col0\" class=\"data row21 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row21_col1\" class=\"data row21 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row21_col2\" class=\"data row21 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row21_col3\" class=\"data row21 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row21_col4\" class=\"data row21 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row21_col5\" class=\"data row21 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row22\" class=\"row_heading level0 row22\" >[PARENT] like</th>\n",
       "      <td id=\"T_a0518_row22_col0\" class=\"data row22 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row22_col1\" class=\"data row22 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row22_col2\" class=\"data row22 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row22_col3\" class=\"data row22 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row22_col4\" class=\"data row22 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row22_col5\" class=\"data row22 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row23\" class=\"row_heading level0 row23\" >[PARENT] especially</th>\n",
       "      <td id=\"T_a0518_row23_col0\" class=\"data row23 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row23_col1\" class=\"data row23 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row23_col2\" class=\"data row23 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row23_col3\" class=\"data row23 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row23_col4\" class=\"data row23 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row23_col5\" class=\"data row23 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row24\" class=\"row_heading level0 row24\" >[PARENT] for example</th>\n",
       "      <td id=\"T_a0518_row24_col0\" class=\"data row24 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row24_col1\" class=\"data row24 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row24_col2\" class=\"data row24 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row24_col3\" class=\"data row24 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row24_col4\" class=\"data row24 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row24_col5\" class=\"data row24 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0518_level0_row25\" class=\"row_heading level0 row25\" >[PARENT] for instance</th>\n",
       "      <td id=\"T_a0518_row25_col0\" class=\"data row25 col0\" >0.000720</td>\n",
       "      <td id=\"T_a0518_row25_col1\" class=\"data row25 col1\" >0.000360</td>\n",
       "      <td id=\"T_a0518_row25_col2\" class=\"data row25 col2\" >0.000000</td>\n",
       "      <td id=\"T_a0518_row25_col3\" class=\"data row25 col3\" >0.000440</td>\n",
       "      <td id=\"T_a0518_row25_col4\" class=\"data row25 col4\" >0.000330</td>\n",
       "      <td id=\"T_a0518_row25_col5\" class=\"data row25 col5\" >0.000430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3f39171c90>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "def highlight_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(s.values), props, '')\n",
    "\n",
    "metrics_table2 = metrics_table.style.apply(highlight_max, \n",
    "                                          props='color:white; background-color:#1FC29D', axis=0).apply(highlight_min, props='color:white; background-color:#FF5555', axis=0)\n",
    "metrics_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f85358-d9c9-4eac-828d-3d323c5133c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
